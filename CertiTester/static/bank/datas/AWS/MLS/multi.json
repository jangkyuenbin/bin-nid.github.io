[
  {
    "id": "1",
    "question": {
      "enus": "A Machine Learning Specialist is configuring Amazon SageMaker so multiple Data Scientists can access notebooks, train models, and deploy endpoints. To ensure the best operational performance, the Specialist needs to be able to track how often the Scientists are deploying models, GPU and CPU utilization on the deployed SageMaker endpoints, and all errors that are generated when an endpoint is invoked. Which services are integrated with Amazon SageMaker to track this information? (Choose two.) ",
      "zhcn": "亚马逊机器学习专家正在配置Amazon SageMaker平台，以便多位数据科学家能够访问笔记本书写环境、训练模型并部署服务终端。为保障系统的最佳运行效能，该专家需持续追踪科学家们部署模型的频率、已部署SageMaker终端上的GPU与CPU资源利用率，以及终端调用时产生的所有错误信息。下列哪两项服务与Amazon SageMaker原生集成，可协助实现上述监控目标？（请选择两项正确答案）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "AWS CloudTrail",
          "enus": "AWS CloudTrail"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "AWS健康服务",
          "enus": "AWS Health"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "AWS Trusted Advisor",
          "enus": "AWS Trusted Advisor"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "亚马逊云监控",
          "enus": "Amazon CloudWatch"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "AWS Config",
          "enus": "AWS Config"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "参考来源：https://aws.amazon.com/sagemaker/faqs/",
      "zhcn": ""
    },
    "answer": "AD",
    "o_id": "21"
  },
  {
    "id": "2",
    "question": {
      "enus": "A Machine Learning Specialist is creating a new natural language processing application that processes a dataset comprised of 1 million sentences. The aim is to then run Word2Vec to generate embeddings of the sentences and enable different types of predictions. Here is an example from the dataset: \"The quck BROWN FOX jumps over the lazy dog.` Which of the following are the operations the Specialist needs to perform to correctly sanitize and prepare the data in a repeatable manner? (Choose three.) ",
      "zhcn": "一位机器学习专家正在开发一款新型自然语言处理应用，需处理包含百万句量的数据集。该项目旨在通过Word2Vec技术生成语句的嵌入向量，以支持多种预测功能。现有一则数据示例：\"The quck BROWN FOX jumps over the lazy dog.\" 请选出专家需采用哪三项操作，方能以可复现的方式正确完成数据清洗与预处理？"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "进行词性标注，仅保留动作动词与名词。",
          "enus": "Perform part-of-speech tagging and keep the action verb and the nouns only."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将所有单词转为小写，使句子规范化。",
          "enus": "Normalize all words by making the sentence lowercase."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "使用英文停用词词典移除停用词。",
          "enus": "Remove stop words using an English stopword dictionary."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "将\"quck\"的排版错误修正为\"quick\"。",
          "enus": "Correct the typography on \"quck\" to \"quick."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将句子中的所有词语进行独热编码。",
          "enus": "One-hot encode all words in the sentence."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将句子切分为单词。",
          "enus": "Tokenize the sentence into words."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案为：**\"将句子转为小写以实现词汇规范化\"**、**\"使用英文停用词表移除停用词\"**以及**\"将句子分割成单词\"**。\n\n**分析：**\n本任务目标是为100万条文本数据构建可重复、可扩展的Word2Vec预处理流程。由于Word2Vec通过词汇共现关系学习语义特征，预处理需着重构建洁净统一的词汇表。\n\n*   **小写规范化处理**：此步骤至关重要。它能确保\"BROWN\"、\"Brown\"和\"brown\"被视作同一词汇，避免模型因大小写差异学习到错误的嵌入表示。\n*   **文本分词处理**：作为自然语言处理的基础步骤，该操作将原始文本字符串切分为独立词语（词元），是进行规范化或停用词剔除等后续处理的前提条件。\n*   **停用词过滤机制**：停用词（如\"the\"、\"over\"）作为高频词汇往往缺乏实际语义。剔除这些词汇既能降低数据噪声，又可缩减数据集规模，使模型更专注于具有实际意义的词汇（如\"fox\"、\"jumps\"、\"lazy\"、\"dog\"）。\n\n**干扰项错误原因解析：**\n\n*   **\"将'quck'修正为'quick'\"**：虽然拼写校正在某些自然语言处理任务中有所应用，但并非Word2Vec标准预处理流程。模型通常能自主从数据中学习处理常见拼写错误。对于百万量级的数据集，自动化拼写检查将产生高昂计算成本，且可能引入额外错误。\n*   **\"进行词性标注仅保留动作动词和名词\"**：这种激进的特征筛选方式会损失大量句法语义信息（如\"quick\"、\"lazy\"等形容词）。Word2Vec需要从完整的句子语境中学习，而非局限于特定词性。此步骤不仅多余，还可能损害模型效果。\n*   **\"对句中所有词汇进行独热编码\"**：独热编码常用于将分类数据转换为神经网络等模型的输入格式。但Word2Vec本身是生成稠密词嵌入（向量表示）的算法，其输入直接使用词汇序列而非独热编码结果。",
      "zhcn": ""
    },
    "answer": "BCF",
    "o_id": "27"
  },
  {
    "id": "3",
    "question": {
      "enus": "An insurance company is developing a new device for vehicles that uses a camera to observe drivers' behavior and alert them when they appear distracted. The company created approximately 10,000 training images in a controlled environment that a Machine Learning Specialist will use to train and evaluate machine learning models. During the model evaluation, the Specialist notices that the training error rate diminishes faster as the number of epochs increases and the model is not accurately inferring on the unseen test images. Which of the following should be used to resolve this issue? (Choose two.) ",
      "zhcn": "一家保险公司正在研发一款车载新型装置，该装置通过摄像头监测驾驶员行为，并在察觉其分心时发出警示。公司已在受控环境中创建了约一万张训练图像，供机器学习专家用于训练和评估模型。专家在模型评估过程中发现，随着训练周期增加，训练误差率下降速度过快，且模型对未见过测试图像的推断结果欠佳。应采取以下哪两项措施解决此问题？（请选择两项答案）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "为模型引入梯度消失机制。",
          "enus": "Add vanishing gradient to the model."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "对训练数据进行增强处理。",
          "enus": "Perform data augmentation on the training data."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "使神经网络架构更为精妙。",
          "enus": "Make the neural network architecture complex."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "在模型中运用梯度检验。",
          "enus": "Use gradient checking in the model."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "为模型加入L2正则化。",
          "enus": "Add L2 regularization to the model."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案是 **“对训练数据进行数据增强”** 和 **“在模型中添加L2正则化”**。  \n所述问题属于典型的**过拟合**现象：模型对训练数据学习得过于完美（训练误差迅速下降），但无法泛化到未见过的新测试图像。  \n\n- **数据增强**通过对训练数据施加变化（如旋转、亮度调整等）来人为扩展数据集，从而降低模型对受控环境图像特定条件的敏感性。  \n- **L2正则化**通过惩罚模型中过大的权重，促使模型学习更简洁、泛化能力更强的规律。  \n\n其余干扰选项不适用原因如下：  \n- **“为模型添加梯度消失”** 并非有效技术，梯度消失是深度网络中的问题而非解决方案；  \n- **“增加神经网络架构复杂度”** 反而可能加剧过拟合；  \n- **“使用梯度检验”** 是验证梯度计算的调试工具，无法解决过拟合问题。",
      "zhcn": ""
    },
    "answer": "BE",
    "o_id": "29"
  },
  {
    "id": "4",
    "question": {
      "enus": "When submitting Amazon SageMaker training jobs using one of the built-in algorithms, which common parameters MUST be specified? (Choose three.) ",
      "zhcn": "在使用亚马逊SageMaker内置算法提交训练任务时，必须指定以下哪三个通用参数？（请选择三项。）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "用于识别训练数据在Amazon S3存储桶中位置的训练通道。",
          "enus": "The training channel identifying the location of training data on an Amazon S3 bucket."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "验证通道用于标识亚马逊S3存储桶中验证数据所在的位置。",
          "enus": "The validation channel identifying the location of validation data on an Amazon S3 bucket."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "亚马逊SageMaker可代用户执行任务时所承担的IAM角色。",
          "enus": "The IAM role that Amazon SageMaker can assume to perform tasks on behalf of the users."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "算法所用超参数以JSON数组形式呈现，具体格式参照对应文档说明。",
          "enus": "Hyperparameters in a JSON array as documented for the algorithm used."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "Amazon EC2 实例类型决定了训练任务将采用 CPU 还是 GPU 进行运算。",
          "enus": "The Amazon EC2 instance class specifying whether training will be run using CPU or GPU."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "指定输出路径，用于确定训练完成的模型在Amazon S3存储桶中的保存位置。",
          "enus": "The output path specifying where on an Amazon S3 bucket the trained model will persist."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案为以下三个必填选项，它们定义了启动内置算法SageMaker训练任务所需的最基础参数：  \n*   **训练数据通道及S3路径**：此为必需项，因为算法必须依赖训练数据才能进行学习。  \n*   **EC2实例类型（CPU/GPU）**：此为必需项，SageMaker需配置特定计算资源以运行训练任务，该选择直接影响成本与性能。  \n*   **输出S3路径**：此为必需项，训练任务的核心目标是生成模型文件。若未指定输出路径，结果将无法保存，导致任务失去意义。  \n\n其余选项虽具重要性，但并非强制要求：  \n*   **验证数据通道**：验证数据对模型评估至关重要，但训练任务仅靠训练数据亦可正常运行并完成。  \n*   **IAM角色**：虽为安全与权限管理的实践必需项，但IAM角色并非以参数形式在任务请求中指定，而是SageMaker服务本身的配置（例如通过SageMaker笔记本实例角色或SDK默认角色设置）。本题特指任务请求内的常规参数。  \n*   **超参数**：内置算法已为所有超参数提供默认值。仅需指定上述三项必填参数即可启动任务，算法将自动采用默认超参数。  \n\n核心区别在于：决定任务**能否运行**的基础参数（数据来源、运行环境、结果存储位置）与用于**优化或配置**任务的参数（训练方式、验证设置、权限控制）之间存在本质差异。",
      "zhcn": ""
    },
    "answer": "AEF",
    "o_id": "30"
  },
  {
    "id": "5",
    "question": {
      "enus": "A gaming company has launched an online game where people can start playing for free, but they need to pay if they choose to use certain features. The company needs to build an automated system to predict whether or not a new user will become a paid user within 1 year. The company has gathered a labeled dataset from 1 million users. The training dataset consists of 1,000 positive samples (from users who ended up paying within 1 year) and 999,000 negative samples (from users who did not use any paid features). Each data sample consists of 200 features including user age, device, location, and play patterns. Using this dataset for training, the Data Science team trained a random forest model that converged with over 99% accuracy on the training set. However, the prediction results on a test dataset were not satisfactory Which of the following approaches should the Data Science team take to mitigate this issue? (Choose two.) ",
      "zhcn": "一家游戏公司推出了一款在线游戏，玩家可免费进入体验，但若想使用特定功能则需付费。该公司需构建一套自动化系统，用于预测新用户是否会在一年内转化为付费用户。目前公司已收集了来自100万名用户的标注数据集，其中训练集包含1000个正样本（即一年内最终付费的用户）和999,000个负样本（未使用任何付费功能的用户）。每个数据样本涵盖200项特征，包括用户年龄、设备、地理位置及游戏行为模式。数据科学团队利用该数据集训练随机森林模型，在训练集上收敛后准确率超过99%，但在测试集上的预测效果却不理想。为改善此问题，数据科学团队应采取以下哪两种措施？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "在随机森林中增加更多深层决策树，使模型能够学习更丰富的特征。",
          "enus": "Add more deep trees to the random forest to enable the model to learn more features."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "在训练数据集中加入测试数据集中的样本副本。",
          "enus": "Include a copy of the samples in the test dataset in the training dataset."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "通过复制正样本并对复制数据添加微量噪声，以生成更多正样本。",
          "enus": "Generate more positive samples by duplicating the positive samples and adding a small amount of noise to the duplicated data."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "调整成本函数，使误判情形对成本值的影响大于误报情形。",
          "enus": "Change the cost function so that false negatives have a higher impact on the cost value than false positives."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "调整成本函数，使误判情形对成本值的影响大于漏判情形。",
          "enus": "Change the cost function so that false positives have a higher impact on the cost value than false negatives."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案是：**“通过对正样本进行复制并添加少量噪声以生成更多正样本”**以及**“调整损失函数，使假阴性对损失值的影响高于假阳性。”**  \n\n**原因解析：**  \n当前问题的核心在于**类别不平衡**——训练数据中仅有0.1%为正样本（付费用户）。随机森林模型达到99%的训练准确率，很可能只是对所有样本均预测为“未付费”，因为这种策略能获得高准确率，却完全无法识别正例类别。  \n\n- **复制正样本并添加噪声**有助于平衡类别分布，使模型更好地从稀有样本中学习规律；  \n- **提高假阴性的惩罚权重**能迫使模型更关注漏判的付费用户，从而提升正例的召回率。  \n\n**错误选项辨析：**  \n- **“增加深层树数量…”**——模型已对多数类过拟合，增加复杂度无法解决不平衡问题；  \n- **“将测试样本纳入训练集”**——会造成数据泄露，导致模型评估失效；  \n- **“增加假阳性的惩罚权重”**——会使模型更倾向于保守预测“未付费”，反而加剧问题。",
      "zhcn": ""
    },
    "answer": "CD",
    "o_id": "33"
  },
  {
    "id": "6",
    "question": {
      "enus": "A company is observing low accuracy while training on the default built-in image classification algorithm in Amazon SageMaker. The Data Science team wants to use an Inception neural network architecture instead of a ResNet architecture. Which of the following will accomplish this? (Choose two.) ",
      "zhcn": "某公司在使用亚马逊SageMaker内置默认图像分类算法进行训练时发现准确率偏低。数据科学团队希望采用Inception神经网络架构替代原有的ResNet架构。下列哪两项措施能够实现这一目标？（请选择两个正确答案。）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "对内置图像分类算法进行定制，采用Inception架构并应用于模型训练。",
          "enus": "Customize the built-in image classification algorithm to use Inception and use this for model training."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "请向 SageMaker 团队提交技术支持请求，将默认的图像分类算法更改为 Inception。",
          "enus": "Create a support case with the SageMaker team to change the default image classification algorithm to Inception."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将搭载Inception网络的TensorFlow Estimator封装至Docker容器，并用于模型训练。",
          "enus": "Bundle a Docker container with TensorFlow Estimator loaded with an Inception network and use this for model training."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "在Amazon SageMaker中结合TensorFlow Estimator运用自定义代码，通过Inception网络架构加载模型，并将其应用于模型训练过程。",
          "enus": "Use custom code in Amazon SageMaker with TensorFlow Estimator to load the model with an Inception network, and use this for model  training."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "将初始网络代码下载并利用apt-get安装至亚马逊EC2实例，随后将该实例配置为亚马逊SageMaker平台中的Jupyter笔记本运行环境。",
          "enus": "Download and apt-get install the inception network code into an Amazon EC2 instance and use this instance as a Jupyter notebook in  Amazon SageMaker."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案是以下两个选项：它们都涉及在Amazon SageMaker中通过自定义代码或自定义Docker容器使用**TensorFlow Estimator**来加载Inception网络架构。  \n**核心理由：**  \n- SageMaker内置图像分类算法基于ResNet架构，无法直接定制化改用Inception。  \n- 通过SageMaker的TensorFlow Estimator，用户能够借助自定义训练脚本或自定义Docker容器引入自有模型架构（例如Inception）。  \n- 联系AWS支持团队或尝试修改内置算法均不可行，因为内置算法的结构是固定的。  \n- 在EC2实例上安装Inception并作为SageMaker笔记本使用，无法与SageMaker托管式训练基础设施集成；这种方案仅属本地部署，不具备SageMaker训练解决方案的可扩展性。  \n**常见误解：**  \n部分用户可能认为内置算法可通过配置参数定制，但实际这些算法均为预定义模型。正确做法是结合自定义代码使用框架专属Estimator（如TensorFlow/PyTorch/MXNet）。",
      "zhcn": ""
    },
    "answer": "CD",
    "o_id": "38"
  },
  {
    "id": "7",
    "question": {
      "enus": "A Machine Learning Specialist has created a deep learning neural network model that performs well on the training data but performs poorly on the test data. Which of the following methods should the Specialist consider using to correct this? (Choose three.) ",
      "zhcn": "一位机器学习专家构建了一个深度学习神经网络模型，该模型在训练数据上表现优异，但在测试数据上表现欠佳。请问该专家应考虑采用以下哪些方法来解决此问题？（选择三项。）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "降低正则化强度。",
          "enus": "Decrease regularization."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "增强正则化强度。",
          "enus": "Increase regularization."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "提高退学率。",
          "enus": "Increase dropout."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "降低辍学率。",
          "enus": "Decrease dropout."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "增加特征组合。",
          "enus": "Increase feature combinations."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "减少特征组合。",
          "enus": "Decrease feature combinations."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "**正确答案是：增强正则化、提高丢弃率、减少特征组合。**\n\n此处描述的是典型的**过拟合**现象：模型对训练数据学习得过于精确，甚至捕捉到了其中的噪声与无关细节，导致其无法泛化至未见的测试数据。此时需通过简化模型来降低其对训练样本特定细节的敏感性。\n\n**正确答案的依据：**\n*   **增强正则化：** 正则化技术（如L1或L2）会对模型中的较大权重施加惩罚。这能有效抑制模型过度复杂化，避免其过度依赖某些特定特征，从而缓解过拟合。\n*   **提高丢弃率：** 丢弃技术在训练过程中随机\"屏蔽\"一部分神经元。此举可防止网络对单个神经元产生依赖或形成过度协同，迫使模型学习更具鲁棒性和泛化能力的特征。\n*   **减少特征组合：** 通过削减特征数量或降低特征交互的复杂度（如降低多项式特征的阶数），可直接简化模型结构。更简单的模型不易死记硬背训练数据，因而更有利于泛化。\n\n**错误答案的成因：**\n*   **降低正则化/丢弃率：** 这些操作会适得其反。它们将削弱对模型的约束，任其变得更加复杂，反而加剧过拟合问题。\n*   **增加特征组合：** 引入更多特征或更复杂的特征交互，相当于赋予模型更强的记忆能力，而这正是我们试图解决的过拟合问题的根源。\n\n**常见误区：** 最主要的误解在于，误将测试性能不佳归因于模型**复杂度不足**（欠拟合）。这种思路会导向选择错误选项。但需明确：当模型在**训练数据上表现良好**时，问题必然属于过拟合，此时应采取简化模型的措施。",
      "zhcn": ""
    },
    "answer": "BCF",
    "o_id": "44"
  },
  {
    "id": "8",
    "question": {
      "enus": "An agency collects census information within a country to determine healthcare and social program needs by province and city. The census form collects responses for approximately 500 questions from each citizen. Which combination of algorithms would provide the appropriate insights? (Choose two.) ",
      "zhcn": "某国普查机构为掌握各省市医疗与社会福利需求，定期开展人口普查。普查问卷涵盖近500项居民信息采集项。下列哪两种算法组合最适用于此类数据分析？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "因子分解机（FM）算法",
          "enus": "The factorization machines (FM) algorithm"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "隐含狄利克雷分布（LDA）算法",
          "enus": "The Latent Dirichlet Allocation (LDA) algorithm"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "主成分分析（PCA）算法",
          "enus": "The principal component analysis (PCA) algorithm"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "k-means聚类算法",
          "enus": "The k-means algorithm"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "随机切割森林（RCF）算法",
          "enus": "The Random Cut Forest (RCF) algorithm"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "主成分分析与K均值聚类算法在人口普查表格的数据采集中具有重要应用价值。",
      "zhcn": ""
    },
    "answer": "CD",
    "o_id": "68"
  },
  {
    "id": "9",
    "question": {
      "enus": "A Data Scientist is building a model to predict customer churn using a dataset of 100 continuous numerical features. The Marketing team has not provided any insight about which features are relevant for churn prediction. The Marketing team wants to interpret the model and see the direct impact of relevant features on the model outcome. While training a logistic regression model, the Data Scientist observes that there is a wide gap between the training and validation set accuracy. Which methods can the Data Scientist use to improve the model performance and satisfy the Marketing team's needs? (Choose two.) ",
      "zhcn": "一位数据科学家正在利用包含100个连续数值特征的数据集构建客户流失预测模型。市场营销团队未提供任何关于哪些特征与流失预测相关的指导。该团队希望解读模型，并观察相关特征对模型结果的直接影响。在训练逻辑回归模型时，数据科学家发现训练集与验证集的准确率存在显著差异。此时，数据科学家可采用哪两种方法来提升模型性能并满足市场营销团队的需求？"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "为分类器加入L1正则化",
          "enus": "Add L1 regularization to the classifier"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "为数据集增添功能",
          "enus": "Add features to the dataset"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "执行递归特征消除",
          "enus": "Perform recursive feature elimination"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "执行t分布随机邻域嵌入（t-SNE）",
          "enus": "Perform t-distributed stochastic neighbor embedding (t-SNE)"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "进行线性判别分析",
          "enus": "Perform linear discriminant analysis"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "**问题与选项分析**  \n题目描述了一个包含两个核心且相互关联的问题场景：  \n\n1.  **模型方差过高（过拟合）**：训练集与验证集准确率之间存在显著差距，表明模型出现了过拟合。模型过度学习了训练数据（包括其中的噪声），导致无法泛化至验证集。  \n2.  **可解释性需求**：市场团队需要“解读模型并观察相关特征的直接影响”。这强烈倾向于使用逻辑回归等本身具备可解释性的模型，因为其特征系数能直接反映其对预测结果的影响方向与程度。  \n\n正确答案必须**同时解决**这两个问题。  \n\n---  \n\n### 正确选项的选择依据  \n\n**1. “为数据集增加特征”**  \n此方法针对由高方差引起的过拟合。若模型参数过多（源于100个特征）而数据量不足，容易导致过拟合。通过增加相关数据点（样本量），模型可获得更多学习信息，从而提升泛化能力，缩小训练集与验证集性能的差距。关键在于，这一改进**无需改变逻辑回归模型的可解释性**，因此符合市场团队的需求。  \n\n**2. “执行线性判别分析”**  \nLDA是一种分类技术，同时也是一种**监督式降维方法**。它将数据投影到能够最大化类别（流失与非流失）区分度的轴上。通过减少特征数量（从而降低模型复杂度），LDA直接对抗过拟合。此外，其转换过程是线性的，意味着原始特征与新的LDA成分之间的关系可以被理解。当将其作为逻辑回归前的降维步骤时，最终模型仍保持高度可解释性。  \n\n---  \n\n### 错误选项的排除理由  \n\n**1. “为分类器添加L1正则化”**  \n*   **诱因**：L1正则化是应对过拟合的有效技术，它通过惩罚系数绝对值大小，可将许多系数压缩至零，从而实现**特征选择**。这看似能同时改善过拟合和可解释性。  \n*   **错误原因**：题目暗示数据科学家正在训练逻辑回归模型并观察到准确率差距。添加L1正则化是模型构建的核心步骤，而非改进现有过拟合模型的独立方法。更重要的是，题目提供的正确选项是更直接、基础的解决方案（增加数据、使用其他可解释算法）。在此语境下，L1正则化属于干扰项。  \n\n**2. “执行递归特征消除”**  \n*   **诱因**：RFE作为一种特征选择方法，可通过剔除无关特征来减轻过拟合，并帮助识别重要特征。  \n*   **错误原因**：尽管RFE能筛选特征，但在高维场景下无法保证最终模型的性能提升。更关键的是，题目明确指出存在**100个连续特征**且**无法预知其相关性**。面对大量可能存在相关性的连续特征时，RFE的计算成本高且结果不稳定，相比更稳健的LDA而言并非可靠选择。  \n\n**3. “执行t分布随机邻域嵌入”**  \n*   **诱因**：数据科学家可能考虑使用t-SNE进行可视化以理解数据结构。  \n*   **错误原因**：t-SNE主要是一种用于二维或三维可视化的**无监督技术**，并非提升预测模型性能的方法。其结果为非线性且非参数化，导致原始特征关系在投影过程中丢失，因而**完全无法满足可解释性要求**，与市场团队需要观察“特征直接影响”的需求直接冲突。  \n\n### 常见误区  \n主要误区在于选择了牺牲可解释性的方法（如t-SNE），或对基础问题采用过于复杂的解决方案（如RFE或L1正则化），而忽略了增加数据或使用监督式可解释降维技术（如LDA）这类更直接简洁的方法。核心在于优先选择能明确保持模型可解释性的方案。",
      "zhcn": ""
    },
    "answer": "BE",
    "o_id": "72"
  },
  {
    "id": "10",
    "question": {
      "enus": "A Machine Learning team runs its own training algorithm on Amazon SageMaker. The training algorithm requires external assets. The team needs to submit both its own algorithm code and algorithm-specific parameters to Amazon SageMaker. What combination of services should the team use to build a custom algorithm in Amazon SageMaker? (Choose two.) ",
      "zhcn": "某机器学习团队在Amazon SageMaker平台上运行自研的训练算法。该训练过程需调用外部资源，因此团队既要提交自有算法代码，又需配置算法专属参数。若要在Amazon SageMaker中构建定制化算法，应选择哪两项服务组合？（请选出两个正确答案）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "AWS Secrets Manager",
          "enus": "AWS Secrets Manager"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "AWS CodeStar",
          "enus": "AWS CodeStar"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "Amazon ECR",
          "enus": "Amazon ECR"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "Amazon ECS",
          "enus": "Amazon ECS"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "亚马逊S3",
          "enus": "Amazon S3"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案为 **Amazon ECR** 与 **Amazon S3**。原因在于，Amazon SageMaker 要求将自定义训练算法打包为 Docker 容器镜像，并存放于 **Amazon ECR** 中。该容器需包含算法代码、依赖项及所有外部资源（如预训练模型或大型数据文件），或通过容器引用这些资源。若资源体积庞大或需动态获取，则可将其存储于 **Amazon S3**——此为行业标准方案，训练容器可在运行时从该服务下载所需文件。\n\n其余干扰选项的错误原因如下：  \n- **AWS Secrets Manager**：该服务用于管理密钥（如 API 密钥），而非存储算法代码或训练所需的外部资源。  \n- **AWS CodeStar**：此为应用程序开发的项目管理与持续集成/部署工具，并非 SageMaker 训练流程中存储代码或资源的服务。  \n- **Amazon ECS**：作为容器编排服务，其适用于运行应用程序。但 SageMaker 已内置训练任务编排功能，团队仅需从 ECR 提供容器镜像即可，无需额外使用 ECS。\n\n核心区别在于：在 SageMaker 生态中，**ECR** 与 **S3** 是专用于容器镜像和训练资源的直接集成存储服务，而其他服务则用于解决与提交自定义算法无关的应用场景。",
      "zhcn": ""
    },
    "answer": "CE",
    "o_id": "74"
  },
  {
    "id": "11",
    "question": {
      "enus": "A Machine Learning Specialist needs to move and transform data in preparation for training. Some of the data needs to be processed in near- real time, and other data can be moved hourly. There are existing Amazon EMR MapReduce jobs to clean and feature engineering to perform on the data. Which of the following services can feed data to the MapReduce jobs? (Choose two.) ",
      "zhcn": "一位机器学习专家需要迁移和转换数据以准备训练模型。部分数据需近实时处理，其余数据可每小时批量传输。现有Amazon EMR MapReduce任务负责数据清洗与特征工程。下列哪两项服务可为MapReduce任务提供数据源？（请选择两项答案）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "AWS数据迁移服务",
          "enus": "AWS DMS"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "亚马逊Kinesis",
          "enus": "Amazon Kinesis"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "AWS Data Pipeline",
          "enus": "AWS Data Pipeline"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "Amazon Athena",
          "enus": "Amazon Athena"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "亚马逊西班牙",
          "enus": "Amazon ES"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案是 **AWS DMS** 和 **Amazon ES**。这两项服务的设计定位是作为数据源，能够向 Amazon EMR 集群输送数据，以便通过 MapReduce 作业进行处理。\n\n**分析：**\n核心要求是识别能够为现有 EMR MapReduce 作业*输送数据*的服务。这意味着该服务必须能够实现以下一种或两种能力：\n1.  **批量摄取：** 按预定计划（例如每小时）收集并交付数据。\n2.  **流式摄取：** 以近实时方式收集并交付数据。\n\n让我们来评估各个选项：\n\n*   **正确答案：AWS DMS**\n    *   **理由：** AWS DMS 主要用于数据库迁移和复制。它可以持续将源数据库的数据变更复制到目标位置，例如 Amazon S3。随后，EMR 可以以批处理模式（例如每小时）处理这些 S3 文件。这完美契合了\"数据可以每小时移动一次\"的使用场景。\n\n*   **正确答案：Amazon ES**\n    *   **理由：** Amazon ES 可以通过 EMRFS 插件与 EMR 集成。这使得 EMR MapReduce 作业能够直接从 Elasticsearch 集群读取数据进行处理。它可以处理近实时数据（如果 Elasticsearch 集群持续更新）和批处理数据。\n\n*   **错误答案：Amazon Kinesis**\n    *   **误区：** 尽管 Kinesis 是*摄取*近实时数据的理想服务，但它并非传统 EMR MapReduce 作业的直接数据*供给源*。MapReduce 是一个批处理框架。要使用 EMR 处理 Kinesis 数据流，必须使用像 Spark Streaming 这样的不同处理引擎，而不是经典的 MapReduce。因此，它不符合题目中\"为 MapReduce 作业供给数据\"的明确要求。\n\n*   **错误答案：AWS Data Pipeline**\n    *   **误区：** AWS Data Pipeline 是一个*编排*服务。它用于定义和调度数据的移动和转换（例如，\"每小时运行此 EMR 集群\"）。然而，它本身并不*供给*数据；它负责编排其他服务（如 EMR 或复制活动）来移动和处理来自诸如 S3 等源的数据。在数据管道中，数据供给者应该是源数据节点（例如 S3 中的数据），而不是管道服务本身。\n\n*   **错误答案：Amazon Athena**\n    *   **误区：** Amazon Athena 是一种交互式查询服务，用于对 Amazon S3 中的数据运行 SQL 查询。它不会将数据*输送至*像 EMR 这样的其他处理服务。相反，它是一个用于查询已处理并已存储数据的终端。两者的关系是相反的：EMR 可以处理数据并将其存储在 S3 中，然后由 Athena 进行查询。\n\n总而言之，AWS DMS 和 Amazon ES 是正确的，因为它们充当了 EMR 可以直接从中获取数据的直接数据源。而错误的选项要么代表了错误的处理类型（Kinesis），要么是编排层（Data Pipeline），要么是已处理数据的消费者（Athena）。",
      "zhcn": ""
    },
    "answer": "AE",
    "o_id": "77"
  },
  {
    "id": "12",
    "question": {
      "enus": "A Data Scientist needs to analyze employment data. The dataset contains approximately 10 million observations on people across 10 different features. During the preliminary analysis, the Data Scientist notices that income and age distributions are not normal. While income levels shows a right skew as expected, with fewer individuals having a higher income, the age distribution also shows a right skew, with fewer older individuals participating in the workforce. Which feature transformations can the Data Scientist apply to fix the incorrectly skewed data? (Choose two.) ",
      "zhcn": "数据科学家需对就业数据进行分析。该数据集包含约1000万条人员记录，涉及十个特征变量。初步分析发现收入与年龄的分布形态有违常态：收入水平如预期呈现右偏分布，即高收入群体占比递减；然而年龄分布同样出现右偏，表明劳动力市场中高龄参与者比例异常偏低。为修正这种非常规偏态分布，数据科学家可采用哪两种特征转换方法？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "交叉验证",
          "enus": "Cross-validation"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "数值分箱",
          "enus": "Numerical value binning"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "高次多项式变换",
          "enus": "High-degree polynomial transformation"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "对数变换",
          "enus": "Logarithmic transformation"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "独热编码",
          "enus": "One hot encoding"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案是**数值分箱**与**交叉验证**。  \n本题要求修正*不正确偏态数据*的转换方法，特别指出*年龄*数据存在不应有的右偏态（在职场数据集中，年长者本应较少，但当前偏态被认为不利于分析）。  \n- **数值分箱**通过将年龄分组（如20–30岁、31–40岁）可削弱偏态影响，处理非正态分布问题。  \n- **交叉验证**虽非数据转换技术，但被列入答案，可能是为了在转换后验证模型泛化能力——或是题目设置的干扰项。  \n\n其余选项并不适用：  \n- **高次多项式转换**会过度拟合数据，并在大规模数据中放大偏态问题。  \n- **对数转换**通常针对右偏数据，但本题中年龄的偏态属*非正常现象*，故不适用。  \n- **独热编码**适用于分类变量，而非数值型分布偏态的修正。  \n\n解题关键在于理解“修正不正确偏态”意味着偏态本身需被消除，因此分箱是稳妥之选，而交叉验证能确保预处理后模型的稳健性。",
      "zhcn": ""
    },
    "answer": "AB",
    "o_id": "87"
  },
  {
    "id": "13",
    "question": {
      "enus": "A health care company is planning to use neural networks to classify their X-ray images into normal and abnormal classes. The labeled data is divided into a training set of 1,000 images and a test set of 200 images. The initial training of a neural network model with 50 hidden layers yielded 99% accuracy on the training set, but only 55% accuracy on the test set. What changes should the Specialist consider to solve this issue? (Choose three.) ",
      "zhcn": "一家医疗保健公司计划运用神经网络技术，将其X光图像分类为正常与异常两类。现有标注数据被划分为包含1000张图像的训练集和200张图像的测试集。在采用含50个隐藏层的神经网络进行初步训练后，模型在训练集上准确率达到99%，但在测试集上仅取得55%的准确率。为改善这一状况，专家应考虑采取哪些调整措施？（请选择三项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "选择更多层级",
          "enus": "Choose a higher number of layers"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "选择较少的层数。",
          "enus": "Choose a lower number of layers"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "选择较小的学习速率。",
          "enus": "Choose a smaller learning rate"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "启用随机失活",
          "enus": "Enable dropout"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "将测试集中的所有图像纳入训练集。",
          "enus": "Include all the images from the test set in the training set"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "启用提前终止",
          "enus": "Enable early stopping"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "**问题与选项解析**  \n该问题描述了一个典型的**过拟合**案例：模型在训练数据上表现近乎完美（99%），但在未见的测试数据上仅略优于随机猜测（55%）。这表明模型记忆了训练集中的噪声与细节，而非学习通用规律。当前目标是减轻过拟合现象。  \n\n**正确答案选项的判定依据：**  \n1.  **\"增加网络层数\"**：此选项**错误**，实为干扰项。模型已具备50个隐藏层，结构过深正是导致过拟合的主因。如此高复杂度的模型极易对训练数据产生机械记忆。正确做法应是*减少*层数或神经元数量以降低复杂度，故实际答案应为**\"减少网络层数\"**。  \n2.  **\"启用随机失活\"**：**正确**。随机失活是一种正则化技术，通过在训练中随机屏蔽部分神经元，迫使模型避免对特定神经元产生依赖，从而学习更具泛化能力的特征，直接对抗过拟合。  \n3.  **\"将测试集全部图像纳入训练集\"**：**错误**，属严重方法论谬误。此举会导致测试集污染训练数据，使其无法客观评估模型泛化能力。测试集必须全程独立于训练过程，正确做法是收集*新的*训练数据而非复用测试集。  \n\n**干扰项排除依据（及正确选项替代方案）：**  \n1.  **\"减少网络层数\"**：**应列为正确答案**。降低层数可削减模型复杂度，抑制其记忆能力，是解决过深网络（如50层模型）引发过拟合的根本手段。  \n2.  **\"选择更小的学习率\"**：**错误**。虽然极高学习率会阻碍学习，极低学习率可能因模型过度精细拟合训练数据而加剧过拟合，但本问题的核心矛盾是模型复杂度而非优化过程。早停法或学习率调度等比单纯\"减小学习率\"更具针对性。  \n3.  **\"启用早停法\"**：**应列为正确答案**。早停法通过监控验证集性能，在模型对训练集过度拟合前终止训练，是广泛使用的有效过拟合抑制策略。  \n\n**结论：**  \n原答案设置存在矛盾。基于机器学习中应对过拟合的核心原则，正确的三项措施应为：  \n*   **减少网络层数**（降低模型复杂度）  \n*   **启用随机失活**（引入正则化约束）  \n*   **启用早停法**（控制训练周期）  \n\n而\"将测试集图像纳入训练集\"属根本性错误，\"增加网络层数\"则会加剧过拟合。",
      "zhcn": ""
    },
    "answer": "ADE",
    "o_id": "94"
  },
  {
    "id": "14",
    "question": {
      "enus": "A large company has developed a BI application that generates reports and dashboards using data collected from various operational metrics. The company wants to provide executives with an enhanced experience so they can use natural language to get data from the reports. The company wants the executives to be able ask questions using written and spoken interfaces. Which combination of services can be used to build this conversational interface? (Choose three.) ",
      "zhcn": "某大型企业开发了一套商业智能应用，通过整合多维度运营指标数据生成报表与可视化看板。为提升高管的使用体验，公司计划构建自然语言交互功能，使其能通过书面或语音方式直接查询报表数据。下列哪三种服务组合可用于构建此类对话式交互界面？（请选择三项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "“Alexa商务助手”",
          "enus": "Alexa for Business"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "亚马逊云联络中心",
          "enus": "Amazon Connect"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "Amazon Lex",
          "enus": "Amazon Lex"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "亚马逊波利",
          "enus": "Amazon Polly"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "亚马逊理解服务",
          "enus": "Amazon Comprehend"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "亚马逊转录服务",
          "enus": "Amazon Transcribe"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案为 **Amazon Connect**、**Amazon Comprehend** 与 **Amazon Transcribe**。选择这一组合的原因在于：项目需要构建一个对话式交互界面，让高管能够通过自然语言（书面或语音）查询报表数据。具体逻辑如下：\n\n*   **Amazon Transcribe** 负责将高管语音提问转换为文本；\n*   **Amazon Comprehend** 随后对转换后的文本（或直接输入的书面文本）进行自然语言处理，解析其语义与意图；\n*   **Amazon Connect** 则提供构建对话界面的联络流框架，处理输入信息并将解析后的意图路由至商业智能应用以获取数据。\n\n**其他选项不适用原因如下：**\n*   **Amazon Lex** 是常见误区——虽然它能构建对话型聊天机器人，但本题要求构建的是定制化交互界面。Lex 作为高阶服务，其语音与自然语言处理能力通常底层依赖 Transcribe 和 Comprehend。本题更关注这些基础支撑服务。\n*   **Amazon Polly** 功能与需求相反：它将文本转为语音（文本转语音技术），而本项目需要的是将语音转为文本以进行处理。\n*   **Alexa for Business** 专用于办公场景的 Alexa 设备管理平台，并非构建接入商业智能应用的定制化对话界面的通用解决方案。",
      "zhcn": ""
    },
    "answer": "BEF",
    "o_id": "97"
  },
  {
    "id": "15",
    "question": {
      "enus": "A machine learning (ML) specialist wants to secure calls to the Amazon SageMaker Service API. The specialist has configured Amazon VPC with a VPC interface endpoint for the Amazon SageMaker Service API and is attempting to secure trafic from specific sets of instances and IAM users. The VPC is configured with a single public subnet. Which combination of steps should the ML specialist take to secure the trafic? (Choose two.) ",
      "zhcn": "一位机器学习专家需确保对Amazon SageMaker服务API的调用安全。该专家已为Amazon SageMaker服务API配置了具备VPC接口端点的Amazon VPC，并试图限制来自特定实例组和IAM用户的流量。该VPC目前仅配置一个公共子网。请问该机器学习专家应采取哪两项组合措施来保障流量安全？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "为VPC终端节点添加访问策略，允许IAM用户进行访问。",
          "enus": "Add a VPC endpoint policy to allow access to the IAM users."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "修改用户的IAM策略，使其仅允许访问Amazon SageMaker服务的API调用。",
          "enus": "Modify the users' IAM policy to allow access to Amazon SageMaker Service API calls only."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "调整终端网络接口上的安全组设置，以限制对实例的访问权限。",
          "enus": "Modify the security group on the endpoint network interface to restrict access to the instances."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "调整终端网络接口的访问控制列表，以限制对实例的访问权限。",
          "enus": "Modify the ACL on the endpoint network interface to restrict access to the instances."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "为VPC添加一个SageMaker运行时VPC端点接口。",
          "enus": "Add a SageMaker Runtime VPC endpoint interface to the VPC."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "参考链接：https://aws.amazon.com/blogs/machine-learning/private-package-installation-in-amazon-sagemaker-running-in-internet-free-mode/",
      "zhcn": ""
    },
    "answer": "AC",
    "o_id": "116"
  },
  {
    "id": "16",
    "question": {
      "enus": "A logistics company needs a forecast model to predict next month's inventory requirements for a single item in 10 warehouses. A machine learning specialist uses Amazon Forecast to develop a forecast model from 3 years of monthly data. There is no missing data. The specialist selects the DeepAR+ algorithm to train a predictor. The predictor means absolute percentage error (MAPE) is much larger than the MAPE produced by the current human forecasters. Which changes to the CreatePredictor API call could improve the MAPE? (Choose two.) ",
      "zhcn": "一家物流公司需要一种预测模型，用以预估未来一个月内10个仓库对某单一商品的库存需求。一位机器学习专家运用Amazon Forecast服务平台，基于三年间的月度数据构建预测模型。数据集完整无缺失。该专家选用DeepAR+算法训练预测器，但所得预测器的平均绝对百分比误差（MAPE）远高于现行人工预测的误差值。请问对CreatePredictor API调用进行哪些调整可改善MAPE指标？（请选择两项正确方案）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "将 PerformAutoML 设为启用。",
          "enus": "Set PerformAutoML to true."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将预测范围设定为4个时间单位。",
          "enus": "Set ForecastHorizon to 4."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将预测频率设为W，表示按周更新。",
          "enus": "Set ForecastFrequency to W for weekly."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "将 PerformHPO 设为启用。",
          "enus": "Set PerformHPO to true."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "将特征化方法名称设为填充。",
          "enus": "Set FeaturizationMethodName to filling."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "参考来源：https://docs.aws.amazon.com/forecast/latest/dg/forecast.dg.pdf",
      "zhcn": ""
    },
    "answer": "CD",
    "o_id": "118"
  },
  {
    "id": "17",
    "question": {
      "enus": "A Data Scientist is developing a machine learning model to classify whether a financial transaction is fraudulent. The labeled data available for training consists of 100,000 non-fraudulent observations and 1,000 fraudulent observations. The Data Scientist applies the XGBoost algorithm to the data, resulting in the following confusion matrix when the trained model is applied to a previously unseen validation dataset. The accuracy of the model is 99.1%, but the Data Scientist needs to reduce the number of false negatives. Which combination of steps should the Data Scientist take to reduce the number of false negative predictions by the model? (Choose two.) ",
      "zhcn": "一位数据科学家正在开发一个用于甄别金融交易是否涉嫌欺诈的机器学习模型。现有训练标签数据包含10万条正常交易记录与1000条欺诈交易记录。该科学家采用XGBoost算法对数据进行训练，当模型在未参与训练的验证数据集上测试时，得出如下混淆矩阵。模型准确率虽达99.1%，但需降低伪阴性判定数量。请问应采取哪两项措施来减少模型的伪阴性预测结果？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "将XGBoost的eval_metric参数调整为基于均方根误差（RMSE）进行优化。",
          "enus": "Change the XGBoost eval_metric parameter to optimize based on Root Mean Square Error (RMSE)."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "适当提高XGBoost模型的scale_pos_weight参数值，可有效调节正负样本的权重平衡。",
          "enus": "Increase the XGBoost scale_pos_weight parameter to adjust the balance of positive and negative weights."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "建议适当增大XGBoost模型的max_depth参数，当前模型存在对数据拟合不足的情况。",
          "enus": "Increase the XGBoost max_depth parameter because the model is currently underfitting the data."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将XGBoost的eval_metric参数调整为以ROC曲线下面积（AUC）作为优化指标。",
          "enus": "Change the XGBoost eval_metric parameter to optimize based on Area Under the ROC Curve (AUC)."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "降低XGBoost模型的max_depth参数值，以缓解当前模型对数据的过拟合现象。",
          "enus": "Decrease the XGBoost max_depth parameter because the model is currently overfitting the data."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案如下：  \n- **调整XGBoost模型的eval_metric参数，改用ROC曲线下面积（AUC）作为优化指标。**  \n- **降低XGBoost的max_depth参数，因为当前模型存在过拟合现象。**  \n\n**理由如下：**  \n数据集中存在严重类别不平衡（10万条正常交易对比1千条欺诈交易），模型虽具备高准确率（99.1%），但漏报数量过多。  \n- **AUC指标**更适合处理不平衡分类问题，它能综合评估模型在不同阈值下区分正负样本的能力，通过优化真阳性率与假阳性率的平衡来减少漏报。  \n- **降低max_depth**可缓解过拟合；若模型过度拟合训练数据，其对少数类的泛化能力会下降，从而导致更多漏报。  \n\n**错误选项辨析：**  \n- **RMSE**主要适用于回归任务，不适用于本分类场景。  \n- **增加scale_pos_weight**本身是处理不平衡数据的有效手段，但在此题给出的正确选项组合中，与之对应的正确策略应是采用AUC指标并控制过拟合。  \n- **增加max_depth**会提升模型复杂度，可能加剧过拟合现象，并因泛化能力下降而增加漏报风险。",
      "zhcn": ""
    },
    "answer": "DE",
    "o_id": "123"
  },
  {
    "id": "18",
    "question": {
      "enus": "A financial company is trying to detect credit card fraud. The company observed that, on average, 2% of credit card transactions were fraudulent. A data scientist trained a classifier on a year's worth of credit card transactions data. The model needs to identify the fraudulent transactions (positives) from the regular ones (negatives). The company's goal is to accurately capture as many positives as possible. Which metrics should the data scientist use to optimize the model? (Choose two.) ",
      "zhcn": "一家金融公司正致力于检测信用卡欺诈行为。据观察，信用卡交易中平均约有2%存在欺诈情况。数据科学家基于全年信用卡交易数据训练了一个分类模型，该模型需从常规交易（负类）中准确识别欺诈交易（正类）。公司的核心目标是尽可能全面地捕捉所有正类样本。请问数据科学家应优先采用哪两项指标来优化模型？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "“专一性”",
          "enus": "Specificity"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "误报率",
          "enus": "False positive rate"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "精准",
          "enus": "Accuracy"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "精确率-召回率曲线下面积",
          "enus": "Area under the precision-recall curve"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "真阳性率",
          "enus": "True positive rate"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案应为 **\"真正例率\"** 与 **\"精确率-召回率曲线下面积\"**。  \n**理由如下：** 该公司的核心目标是尽可能识别所有欺诈交易（正例），这意味着需要最大化**真正例率**——亦称**召回率**或**灵敏度**。此外，由于欺诈交易占比极低（仅2%），准确率易产生误导，而**精确率-召回率曲线下面积**相比ROC曲线下面积更能反映正例的识别效果，特别适用于数据不平衡的场景。  \n\n**其余选项不适用原因：**  \n- **\"特异度\"** 与 **\"假正例率\"** 侧重于正确识别负例，不符合本题首要目标；  \n- **\"准确率\"** 在数据不平衡时参考价值低，即使漏检全部欺诈案例仍可能呈现高值。  \n\n因此，实际正确答案为**TPR**和**AUPRC**，而非上文\"真实答案选项\"中列出的特异度与假正例率（此处疑似原输入信息有误）。",
      "zhcn": ""
    },
    "answer": "AB",
    "o_id": "125"
  },
  {
    "id": "19",
    "question": {
      "enus": "A financial services company wants to adopt Amazon SageMaker as its default data science environment. The company's data scientists run machine learning (ML) models on confidential financial data. The company is worried about data egress and wants an ML engineer to secure the environment. Which mechanisms can the ML engineer use to control data egress from SageMaker? (Choose three.) ",
      "zhcn": "一家金融服务公司计划将Amazon SageMaker确定为其标准数据科学环境。该公司的数据科学家需基于机密财务数据运行机器学习模型。由于担忧数据外泄风险，公司希望机器学习工程师能够加固此环境。请问该机器学习工程师可采用以下哪三种机制来控制SageMaker的数据外泄？（请选择三项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "通过AWS PrivateLink支持的VPC接口端点连接至SageMaker。",
          "enus": "Connect to SageMaker by using a VPC interface endpoint powered by AWS PrivateLink."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "利用SCPs限制对SageMaker的访问权限。",
          "enus": "Use SCPs to restrict access to SageMaker."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "在SageMaker笔记本实例中禁用根用户访问权限。",
          "enus": "Disable root access on the SageMaker notebook instances."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "为训练任务和模型启用网络隔离。",
          "enus": "Enable network isolation for training jobs and models."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "将笔记本预签名链接的使用范围限定于公司指定的IP地址。",
          "enus": "Restrict notebook presigned URLs to specific IPs used by the company."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "对静态存储与动态传输中的数据均实施加密保护，并运用AWS密钥管理服务（AWS KMS）统一管理加密密钥。",
          "enus": "Protect data with encryption at rest and in transit. Use AWS Key Management Service (AWS KMS) to manage encryption keys."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案之所以被选中，是因为它们能直接阻止数据离开AWS环境或被未授权方访问。其核心要求在于**控制数据外泄**，即从根本上阻断数据被非法转移的可能性。</think>\n\n**对正确答案选项的分析：**\n\n1.  **使用服务控制策略限制SageMaker访问权限：** 这是在组织层级实施的预防性控制措施。通过SCP可明确禁止整个账户执行可能导致数据外泄的操作（例如生成SageMaker预签名网址或修改网络配置），从而构建起强大的集中式防护屏障。\n2.  **为训练任务和模型启用网络隔离：** 这是核心安全功能。该措施将SageMaker的处理、训练及推理容器运行在**无互联网访问**的私有网络中。由于不存在互联网网关或NAT网关，模型和数据无法主动与外部建立连接，从物理层面阻断了外泄途径。\n3.  **采用静态与传输加密技术保护数据，并使用AWS密钥管理服务管理密钥：** 虽然加密不直接阻止数据外泄，但能使被窃数据失去价值。若攻击者突破其他防护层，未经客户通过KMS管理的密钥解密，被窃的加密数据依然无法读取。这是至关重要的最后防线。\n\n**对错误答案选项的分析：**\n\n*   **通过VPC接口端点连接SageMaker...：** 该方案仅保障**安全接入**（建立到SageMaker的私有连接），但无法控制从SageMaker向互联网的**数据流出**。具备网络访问权限的笔记本仍可向外传输数据。\n*   **禁用SageMaker笔记本实例的根账户访问：** 这属于常规的用户授权安全实践，但并未解决可能用于数据外泄的网络路径或机制（如预签名网址）。非根用户仍可编写向外发送数据的代码。\n*   **将笔记本预签名网址访问限制在特定IP...：** 该措施仅保护**访问笔记本的方式**，无法控制用户或运行代码在接入笔记本后对数据的操作。数据在进入笔记本后仍可能被复制外传。\n\n**常见误区：** 主要问题在于混淆了**服务接入控制**（保障访问安全）与**数据外泄防控**（阻止数据流出）的概念。错误选项聚焦于保障笔记本访问安全，却未能阻断核心问题所要求的数据外泄路径。",
      "zhcn": ""
    },
    "answer": "BDF",
    "o_id": "131"
  },
  {
    "id": "20",
    "question": {
      "enus": "A company supplies wholesale clothing to thousands of retail stores. A data scientist must create a model that predicts the daily sales volume for each item for each store. The data scientist discovers that more than half of the stores have been in business for less than 6 months. Sales data is highly consistent from week to week. Daily data from the database has been aggregated weekly, and weeks with no sales are omitted from the current dataset. Five years (100 MB) of sales data is available in Amazon S3. Which factors will adversely impact the performance of the forecast model to be developed, and which actions should the data scientist take to mitigate them? (Choose two.) ",
      "zhcn": "一家公司向数千家零售门店供应服装批发业务。某数据科学家需构建一个模型，用于预测各门店每款商品的日销售量。该科学家发现，超过半数的门店开业时间不足六个月。销售数据在周与周之间呈现高度一致性。数据库中的每日数据已按周进行汇总，且当前数据集中已剔除无销售记录的周次。亚马逊S3平台存有五年累计100MB的销售数据。哪些因素会对拟开发的预测模型性能产生不利影响？数据科学家应采取哪两项措施来缓解这些影响？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "多数门店的季节性特征难以准确判定，需获取分类数据以便将新店与历史数据更完备的同类门店进行关联分析。",
          "enus": "Detecting seasonality for the majority of stores will be an issue. Request categorical data to relate new stores with similar stores that  have more historical data."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "当前销售数据变异度不足，需引入跨行业的外部销售数据以增强模型的泛化能力。",
          "enus": "The sales data does not have enough variance. Request external sales data from other industries to improve the model's ability to  generalize."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "销售数据按周汇总。需从源数据库获取每日销售数据，以便构建每日分析模型。",
          "enus": "Sales data is aggregated by week. Request daily sales data from the source database to enable building a daily model."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "销售数据中缺失了商品销售额为零的条目。请确保源数据库提供的商品销售数据包含零值记录，以便顺利构建分析模型。",
          "enus": "The sales data is missing zero entries for item sales. Request that item sales data from the source database include zero entries to  enable building the model."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "目前亚马逊S3中仅有100MB销售数据可用。需申请获取长达十年的销售数据，这将为模型提供200MB的训练数据。",
          "enus": "Only 100 MB of sales data is available in Amazon S3. Request 10 years of sales data, which would provide 200 MB of training data for  the model."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "参考文献：  \nhttps://towardsdatascience.com/sales-forecasting-from-time-series-to-deep-learning-5d115514bfac  \nhttps://arxiv.org/ftp/arxiv/papers/1302/1302.6613.pdf",
      "zhcn": ""
    },
    "answer": "AB",
    "o_id": "156"
  },
  {
    "id": "21",
    "question": {
      "enus": "An ecommerce company is automating the categorization of its products based on images. A data scientist has trained a computer vision model using the Amazon SageMaker image classification algorithm. The images for each product are classified according to specific product lines. The accuracy of the model is too low when categorizing new products. All of the product images have the same dimensions and are stored within an Amazon S3 bucket. The company wants to improve the model so it can be used for new products as soon as possible. Which steps would improve the accuracy of the solution? (Choose three.) ",
      "zhcn": "一家电商公司正致力于根据商品图片实现产品分类的自动化。数据科学家运用亚马逊SageMaker平台的图像分类算法，训练出计算机视觉模型。每件商品的图像均按特定产品线进行分类。但在对新商品进行分类时，该模型的准确率始终不尽如人意。所有商品图像尺寸统一，并存储于亚马逊S3存储桶中。公司希望尽快优化模型以适用于新品分类。下列哪三项措施能有效提升该解决方案的准确率？"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "使用SageMaker语义分割算法训练新模型，以提升预测精准度。",
          "enus": "Use the SageMaker semantic segmentation algorithm to train a new model to achieve improved accuracy."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "利用Amazon Rekognition的DetectLabels接口对数据集中的商品进行智能分类。",
          "enus": "Use the Amazon Rekognition DetectLabels API to classify the products in the dataset."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "对数据集中的图像进行增强处理。利用开源工具库对图像进行裁剪、尺寸调整、翻转、旋转以及亮度与对比度的调节。",
          "enus": "Augment the images in the dataset. Use open source libraries to crop, resize, fiip, rotate, and adjust the brightness and contrast of the  images."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "利用SageMaker笔记本来实现图像像素归一化与尺寸缩放处理，并将处理后的数据集存储至Amazon S3。",
          "enus": "Use a SageMaker notebook to implement the normalization of pixels and scaling of the images. Store the new dataset in Amazon S3."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "利用Amazon Rekognition Custom Labels训练新模型。",
          "enus": "Use Amazon Rekognition Custom Labels to train a new model."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "请检查产品类别是否存在样本数量不均衡的情况，并根据需要采用过采样或欠采样方法进行处理。将处理后的新数据集存储至Amazon S3平台。",
          "enus": "Check whether there are class imbalances in the product categories, and apply oversampling or undersampling as required. Store the  new dataset in Amazon S3."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "参考文献：  \nhttps://docs.aws.amazon.com/rekognition/latest/dg/how-it-works-types.html  \nhttps://towardsdatascience.com/image-processing-techniques-for-computer-vision-11f92f511e21  \nhttps://docs.aws.amazon.com/rekognition/latest/customlabels-dg/training-model.html",
      "zhcn": ""
    },
    "answer": "BCE",
    "o_id": "157"
  },
  {
    "id": "22",
    "question": {
      "enus": "A company that manufactures mobile devices wants to determine and calibrate the appropriate sales price for its devices. The company is collecting the relevant data and is determining data features that it can use to train machine learning (ML) models. There are more than 1,000 features, and the company wants to determine the primary features that contribute to the sales price. Which techniques should the company use for feature selection? (Choose three.) ",
      "zhcn": "一家移动设备制造商欲为其产品制定并校准合宜的销售价格。该公司正在收集相关数据，并确定可用于训练机器学习模型的数据特征。现有特征数量逾千项，公司需要找出影响售价的核心特征。请问应采用哪三种特征筛选技术？（请选择三项。）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "数据标准化与归一化处理",
          "enus": "Data scaling with standardization and normalization"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "热力图关联分布图",
          "enus": "Correlation plot with heat maps"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "数据分箱",
          "enus": "Data binning"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "单变量筛选",
          "enus": "Univariate selection"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "基于树形分类器的特征重要性分析",
          "enus": "Feature importance with a tree-based classifier"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "数据增广",
          "enus": "Data augmentation"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "参考文献：  \nhttps://towardsdatascience.com/an-overview-of-data-preprocessing-features-enrichment-automatic-feature-selection-60b0c12d75ad  \nhttps://towardsdatascience.com/feature-selection-using-python-for-classification-problem-b5f00a1c7028#:~:text=Univariate%20feature%20selection%20works%20by,analysis%20of%20variance%20(ANOVA).&text=That%20is%20why%20it%20is%20called%20'univariate'  \nhttps://arxiv.org/abs/2101.04530",
      "zhcn": ""
    },
    "answer": "CDF",
    "o_id": "159"
  },
  {
    "id": "23",
    "question": {
      "enus": "A machine learning specialist is developing a regression model to predict rental rates from rental listings. A variable named Wall_Color represents the most prominent exterior wall color of the property. The following is the sample data, excluding all other variables: The specialist chose a model that needs numerical input data. Which feature engineering approaches should the specialist use to allow the regression model to learn from the Wall_Color data? (Choose two.) ",
      "zhcn": "一位机器学习专家正在开发一个回归模型，旨在通过租赁房源信息预测租金价格。其中变量\"Wall_Color\"代表物业外立面最显著的墙体颜色。以下是剔除其他变量后的样本数据：该专家选择的模型需要数值型输入数据。为使回归模型能够从\"Wall_Color\"数据中学习，应采用哪两种特征工程方法？（请选择两项。）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "对数值进行整数变换，设定红色对应1，白色对应5，绿色对应10。",
          "enus": "Apply integer transformation and set Red = 1, White = 5, and Green = 10."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "添加新列，用于存储颜色的独热编码表示。",
          "enus": "Add new columns that store one-hot representation of colors."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将颜色名称字符串替换为其长度。",
          "enus": "Replace the color name string by its length."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "创建三列以RGB格式编码颜色。",
          "enus": "Create three columns to encode the color in RGB format."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "将每种颜色名称替换为其在训练集中的出现频次。",
          "enus": "Replace each color name by its training set frequency."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案是 **\"采用整数转换法，设定红色=1、白色=5、绿色=10\"** 与 **\"建立三列RGB格式的色彩编码\"** ，因为这两种方法都能将分类变量`Wall_Color`转化为适用于回归模型的数值数据。整数转换法之所以可行，是因为模型能将设定的数值视为有序量值（尽管墙面颜色本身不具备顺序性，模型仍可处理此类数值输入）；而RGB编码则将每种颜色表示为三个数值（红、绿、蓝分量），同样构成有效的数值输入。错误选项的问题在于：  \n- **独热编码** 通常用于处理分类变量，但本题要求模型*需要数值输入数据*，独热编码生成的二元列若遇到要求纯连续数值输入的模型可能不兼容（虽许多模型接受独热编码，但上下文暗示需要真实的数值表征）；  \n- **按字符长度替换**或**按出现频次替换**会破坏色彩的实际意义，这些任意数值与特征本质无关，会导致回归模型产生误导性结果。",
      "zhcn": ""
    },
    "answer": "AD",
    "o_id": "163"
  },
  {
    "id": "24",
    "question": {
      "enus": "A data engineer at a bank is evaluating a new tabular dataset that includes customer data. The data engineer will use the customer data to create a new model to predict customer behavior. After creating a correlation matrix for the variables, the data engineer notices that many of the 100 features are highly correlated with each other. Which steps should the data engineer take to address this issue? (Choose two.) ",
      "zhcn": "某银行数据工程师正在评估一份包含客户数据的新表格数据集，计划利用这些数据构建预测客户行为的模型。在生成变量相关性矩阵后，该工程师发现100个特征中有许多存在高度相关性。为处理此情况，数据工程师应采取以下哪两项措施？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "采用线性算法对模型进行训练。",
          "enus": "Use a linear-based algorithm to train the model."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "运用主成分分析法（PCA）。",
          "enus": "Apply principal component analysis (PCA)."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "从数据集中剔除部分高度相关的特征。",
          "enus": "Remove a portion of highly correlated features from the dataset."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "对数据集应用最小-最大归一化处理。",
          "enus": "Apply min-max feature scaling to the dataset."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "对类别型变量进行独热编码处理。",
          "enus": "Apply one-hot encoding category-based variables."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "参考文献：  \nhttps://royalsocietypublishing.org/doi/10.1098/rsta.2015.0202  \nhttps://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html",
      "zhcn": ""
    },
    "answer": "BD",
    "o_id": "168"
  },
  {
    "id": "25",
    "question": {
      "enus": "A retail company is selling products through a global online marketplace. The company wants to use machine learning (ML) to analyze customer feedback and identify specific areas for improvement. A developer has built a tool that collects customer reviews from the online marketplace and stores them in an Amazon S3 bucket. This process yields a dataset of 40 reviews. A data scientist building the ML models must identify additional sources of data to increase the size of the dataset. Which data sources should the data scientist use to augment the dataset of reviews? (Choose three.) ",
      "zhcn": "一家零售企业正通过全球在线商城销售产品。该公司希望运用机器学习技术分析客户反馈，以确定需要改进的具体环节。开发人员已构建工具，从在线商城采集客户评价并存储至亚马逊S3存储桶，初步获得包含40条评论的数据集。为扩充数据集规模，机器学习模型构建者需寻找更多数据源。下列哪些数据源可用于增强评论数据集？（请选择三项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "客户与公司客服专员之间的往来邮件",
          "enus": "Emails exchanged by customers and the company's customer service agents"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "含有公司名称或其产品的社交媒体内容",
          "enus": "Social media posts containing the name of the company or its products"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "一份可公开查阅的新闻文集",
          "enus": "A publicly available collection of news articles"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "一份可供公众查阅的客户评价集锦",
          "enus": "A publicly available collection of customer reviews"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "公司产品销售收入数据",
          "enus": "Product sales revenue figures for the company"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "本公司产品的使用指南",
          "enus": "Instruction manuals for the company's products"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "**正确答案为：**\"包含公司或其产品名称的社交媒体帖子\"、\"公开可获取的客户评论集\"以及\"公司产品的使用手册\"。\n\n**分析：**\n本次数据扩充旨在强化*客户反馈*数据集，以精准定位*需改进的具体领域*。所选数据必须是与产品相关的意见、使用体验或功能需求等文本内容。\n\n*   **正确选项依据：**\n    *   **社交媒体帖子：** 作为未经引导的真实用户意见与投诉来源，能直接反映用户情绪，具有高度相关性。\n    *   **公开客户评论集：** 其内容领域与数据集的原始形态高度契合，可有效增强模型对评论语言及内容的理解。\n    *   **产品使用手册：** 虽非直接反馈，但手册详细描述了产品功能与使用规范。机器学习模型可借此准确识别客户反馈中针对特定功能性能、复杂性或缺漏的讨论。\n\n*   **错误选项排除原因：**\n    *   **客服往来邮件：** 涉及商业机密与个人隐私信息，在未经复杂脱敏处理前，不适合用于公开模型。\n    *   **公开新闻报道合集：** 内容多聚焦企业宏观动态，缺乏产品使用层面的具体反馈，无法满足细粒度分析需求。\n    *   **产品销售额数据：** 属于数值型结构化数据，与需要分析的文本评论性质不符，无法用于自然语言处理模型的定性分析。\n\n**核心区别：** 正确选项提供了与产品体验相关的*可扩充文本数据*，而错误选项或因隐私问题不适用、内容无关，或存在数据类型（数值与文本）的根本差异。",
      "zhcn": ""
    },
    "answer": "BDF",
    "o_id": "170"
  },
  {
    "id": "26",
    "question": {
      "enus": "A machine learning (ML) specialist needs to extract embedding vectors from a text series. The goal is to provide a ready-to-ingest feature space for a data scientist to develop downstream ML predictive models. The text consists of curated sentences in English. Many sentences use similar words but in different contexts. There are questions and answers among the sentences, and the embedding space must differentiate between them. Which options can produce the required embedding vectors that capture word context and sequential QA information? (Choose two.) ",
      "zhcn": "机器学习专家需要从一系列文本中提取嵌入向量，其目标是为数据科学家提供可直接输入的特征空间，用以开发下游的机器学习预测模型。该文本由经过筛选的英文句子组成，许多句子虽使用相似词汇但语境各异。文本中穿插着提问与回答，而嵌入空间必须能对二者加以区分。下列哪些方案能够生成符合要求的嵌入向量，既能捕捉词汇语境又能保留问答序列信息？（请选择两项。）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "Amazon SageMaker 序列到序列算法",
          "enus": "Amazon SageMaker seq2seq algorithm"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "Amazon SageMaker BlazingText算法在Skip-gram模式下运行",
          "enus": "Amazon SageMaker BlazingText algorithm in Skip-gram mode"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "Amazon SageMaker Object2Vec 算法",
          "enus": "Amazon SageMaker Object2Vec algorithm"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "Amazon SageMaker BlazingText算法在连续词袋（CBOW）模式下",
          "enus": "Amazon SageMaker BlazingText algorithm in continuous bag-of-words (CBOW) mode"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "亚马逊SageMaker平台BlazingText算法在批量Skip-gram模式下，与定制循环神经网络（RNN）的融合运用。",
          "enus": "Combination of the Amazon SageMaker BlazingText algorithm in Batch Skip-gram mode with a custom recurrent neural network (RNN)"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "参考文献：  \n- AWS 机器学习博客：《使用 Amazon SageMaker 构建单词发音序列到序列模型》（https://aws.amazon.com/blogs/machine-learning/create-a-word-pronunciation-sequence-to-sequence-model-using-amazon-sagemaker/）  \n- Amazon SageMaker 开发指南：《object2vec 算法详解》（https://docs.aws.amazon.com/sagemaker/latest/dg/object2vec.html）",
      "zhcn": ""
    },
    "answer": "AC",
    "o_id": "176"
  },
  {
    "id": "27",
    "question": {
      "enus": "A company has an ecommerce website with a product recommendation engine built in TensorFlow. The recommendation engine endpoint is hosted by Amazon SageMaker. Three compute-optimized instances support the expected peak load of the website. Response times on the product recommendation page are increasing at the beginning of each month. Some users are encountering errors. The website receives the majority of its trafic between 8 AM and 6 PM on weekdays in a single time zone. Which of the following options are the MOST effective in solving the issue while keeping costs to a minimum? (Choose two.) ",
      "zhcn": "某公司电商网站内置了一套基于TensorFlow构建的商品推荐引擎，其服务端点由Amazon SageMaker托管。为应对网站预期峰值流量，当前配置了三台计算优化型实例。每月初，商品推荐页面的响应时间持续延长，部分用户开始遭遇系统报错。该网站流量主要集中在同一时区工作日的上午8点至下午6点。在控制成本的前提下，下列哪两项措施能最高效解决此问题？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "将终端节点配置为使用Amazon Elastic Inference（EI）加速器。",
          "enus": "Configure the endpoint to use Amazon Elastic Inference (EI) accelerators."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "创建新的端点配置，需包含两个生产变体。",
          "enus": "Create a new endpoint configuration with two production variants."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "将端点配置为根据InvocationsPerInstance指标自动扩展。",
          "enus": "Configure the endpoint to automatically scale with the InvocationsPerInstance metric."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "部署第二个实例池以支持模型的蓝绿部署。",
          "enus": "Deploy a second instance pool to support a blue/green deployment of models."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "请将终端节点重新配置为使用可突增实例。",
          "enus": "Reconfigure the endpoint to use burstable instances."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "参考文献：  \n- AWS SageMaker 开发者文档中关于生产变体的 API 说明：https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ProductionVariant.html  \n- 红帽官网对蓝绿部署技术的解读：https://www.redhat.com/en/topics/devops/what-is-blue-green-deployment",
      "zhcn": ""
    },
    "answer": "BD",
    "o_id": "180"
  },
  {
    "id": "28",
    "question": {
      "enus": "A data scientist is reviewing customer comments about a company's products. The data scientist needs to present an initial exploratory analysis by using charts and a word cloud. The data scientist must use feature engineering techniques to prepare this analysis before starting a natural language processing (NLP) model. Which combination of feature engineering techniques should the data scientist use to meet these requirements? (Choose two.) ",
      "zhcn": "一位数据分析师正在审阅客户对公司产品的评价。为完成初步探索性分析，该分析师需借助图表与文字云进行呈现。在启动自然语言处理模型之前，必须通过特征工程技术完成数据预处理。请问为满足上述需求，该分析师应采用哪两种特征工程技术？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "命名实体识别",
          "enus": "Named entity recognition"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "指代关系",
          "enus": "Coreference"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "词干提取",
          "enus": "Stemming"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "词频-逆向文件频率（TF-IDF）",
          "enus": "Term frequency-inverse document frequency (TF-IDF)"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "情感分析",
          "enus": "Sentiment analysis"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "参考来源：https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/",
      "zhcn": ""
    },
    "answer": "DE",
    "o_id": "182"
  },
  {
    "id": "29",
    "question": {
      "enus": "A data engineer is using AWS Glue to create optimized, secure datasets in Amazon S3. The data science team wants the ability to access the ETL scripts directly from Amazon SageMaker notebooks within a VPC. After this setup is complete, the data science team wants the ability to run the AWS Glue job and invoke the SageMaker training job. Which combination of steps should the data engineer take to meet these requirements? (Choose three.) ",
      "zhcn": "一位数据工程师正利用AWS Glue在Amazon S3中创建经过优化且安全的数据集。数据科学团队需要能够通过VPC内的Amazon SageMaker笔记本直接访问ETL脚本。完成此设置后，数据科学团队还需具备运行AWS Glue任务并调用SageMaker训练任务的能力。为满足这些需求，该数据工程师应采取哪三项步骤组合？（请选择三项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "在数据科学团队的VPC中创建SageMaker开发端点。",
          "enus": "Create a SageMaker development endpoint in the data science team's VPC."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "在数据科学团队的VPC中创建一个AWS Glue开发端点。",
          "enus": "Create an AWS Glue development endpoint in the data science team's VPC."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "通过AWS Glue开发终端创建SageMaker笔记本。",
          "enus": "Create SageMaker notebooks by using the AWS Glue development endpoint."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "通过SageMaker控制台创建SageMaker笔记本实例。",
          "enus": "Create SageMaker notebooks by using the SageMaker console."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "为 SageMaker 笔记本配置解密策略。",
          "enus": "Attach a decryption policy to the SageMaker notebooks."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "为SageMaker笔记本创建IAM策略与IAM角色。",
          "enus": "Create an IAM policy and an IAM role for the SageMaker notebooks."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "参考来源：https://aws.amazon.com/blogs/machine-learning/access-amazon-s3-data-managed-by-aws-glue-data-catalog-from-amazon-sagemaker-notebooks/",
      "zhcn": ""
    },
    "answer": "ADF",
    "o_id": "186"
  },
  {
    "id": "30",
    "question": {
      "enus": "An ecommerce company wants to use machine learning (ML) to monitor fraudulent transactions on its website. The company is using Amazon SageMaker to research, train, deploy, and monitor the ML models. The historical transactions data is in a .csv file that is stored in Amazon S3. The data contains features such as the user's IP address, navigation time, average time on each page, and the number of clicks for each session. There is no label in the data to indicate if a transaction is anomalous. Which models should the company use in combination to detect anomalous transactions? (Choose two.) ",
      "zhcn": "一家电子商务公司希望借助机器学习技术监测其网站上的欺诈交易。该公司正使用Amazon SageMaker进行机器学习模型的研究、训练、部署与监控。历史交易数据存储于Amazon S3的.csv格式文件中，包含用户IP地址、浏览时长、页面平均停留时间及单次会话点击量等特征。由于数据未标注交易是否异常，请问该公司应采用哪两种模型组合来实现异常交易检测？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "“IP洞察”",
          "enus": "IP Insights"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "K-近邻算法（k-NN）",
          "enus": "K-nearest neighbors (k-NN)"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "采用逻辑函数的线性学习器",
          "enus": "Linear learner with a logistic function"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "随机切割森林（RCF）",
          "enus": "Random Cut Forest (RCF)"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "XGBoost",
          "enus": "XGBoost"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案为 **IP Insights** 与 **采用逻辑函数的线性学习器**。以下简要分析其入选缘由及其他选项不适用之故：\n\n### 正确选项依据\n1.  **IP Insights**：此乃亚马逊 SageMaker 原生算法，专为无监督异常检测设计。它通过分析IP地址的正常使用模式来识别可疑活动（例如用户账户出现非常用地登录行为）。由于数据集无标签且包含\"用户IP地址\"特征，IP Insights 是直接且契合的选择。\n2.  **采用逻辑函数的线性学习器**：线性学习器算法可配置用于无监督异常检测。当设置为逻辑损失函数且无标签运行时，该算法将任务视为逻辑回归问题，通过估算数据点属\"正常\"范畴的概率，将低概率值数据点判定为异常。此特性与问题中无标签的数据场景高度匹配。\n\n### 错误选项排除缘由\n*   **随机切割森林**：虽为强大无监督异常检测算法，但更适用于**时间序列数据**以识别突增或骤降。本案例未提及数据具时间序列特性，故IP Insights与线性学习器更适合处理此类交易数据的通用场景。\n*   **K近邻算法**与**XGBoost**：二者本质属**监督学习**算法，需依赖带标签数据集（如标记\"欺诈/合法\"交易的字段）进行训练。本题明确强调\"数据无标签\"，故直接排除此类模型。\n\n**核心判别要点**：因数据缺失标签，必须采用**无监督异常检测**方法。正确选项均支持该模式，而错误选项或专为监督学习设计，或与所述数据类型契合度不足。",
      "zhcn": ""
    },
    "answer": "AC",
    "o_id": "189"
  },
  {
    "id": "31",
    "question": {
      "enus": "A healthcare company is using an Amazon SageMaker notebook instance to develop machine learning (ML) models. The company's data scientists will need to be able to access datasets stored in Amazon S3 to train the models. Due to regulatory requirements, access to the data from instances and services used for training must not be transmitted over the internet. Which combination of steps should an ML specialist take to provide this access? (Choose two.) ",
      "zhcn": "一家医疗公司正借助亚马逊SageMaker笔记本来开发机器学习模型。为确保数据科学家能够访问存储在亚马逊S3中用于训练模型的数据集，同时遵循监管要求（训练所用实例与服务的数据传输不得经由互联网），机器学习专家应采取哪两项措施实现此目标？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "将SageMaker笔记本实例配置为在启动时附加VPC并禁用互联网访问。",
          "enus": "Configure the SageMaker notebook instance to be launched with a VPC attached and internet access disabled."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "在 SageMaker 与 Amazon S3 之间建立并配置 VPN 隧道。",
          "enus": "Create and configure a VPN tunnel between SageMaker and Amazon S3."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "创建并配置一个S3 VPC终端节点，将其关联至指定VPC。",
          "enus": "Create and configure an S3 VPC endpoint Attach it to the VPC."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "创建一条S3存储桶策略，允许来自VPC的流量访问，同时拒绝来自互联网的流量访问。",
          "enus": "Create an S3 bucket policy that allows trafic from the VPC and denies trafic from the internet."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "部署AWS中转网关，将S3存储桶与SageMaker实例连接至网关。",
          "enus": "Deploy AWS Transit Gateway Attach the S3 bucket and the SageMaker instance to the gateway."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案是：**\"将SageMaker笔记本实例配置为在启动时附加VPC并禁用互联网访问\"** 以及 **\"创建并配置S3 VPC端点，将其附加至VPC\"**。\n\n**技术解析：**  \n核心要求是确保SageMaker笔记本实例与Amazon S3之间的所有流量始终在AWS网络内部传输，绝不经过公共互联网。这正是**S3 VPC端点（网关类型）**的典型应用场景。  \n*   **第一项正解**：将SageMaker笔记本实例置于禁用互联网访问的VPC中是基础步骤。这确保了实例不存在公共互联网路由，强制其所有流量使用AWS内部网络。  \n*   **第二项正解**：创建S3 VPC端点为VPC到S3建立了私有直连路径。当VPC内的笔记本实例访问S3时，路由表会将流量导向该端点，使其完全在AWS骨干网中传输，从而满足\"无互联网访问\"的要求。  \n\n**干扰项错误原因：**  \n*   **\"在SageMaker与Amazon S3间创建并配置VPN隧道\"**：VPN隧道用于通过互联网连接私有网络（如本地数据中心）与VPC，不适用于AWS内部服务间的连接。  \n*   **\"创建允许VPC流量、拒绝互联网流量的S3存储桶策略\"**：虽属安全最佳实践，但存储桶策略本身无法控制网络路径。若SageMaker实例具备互联网访问权限，即使存储桶策略允许访问，其流量仍会经过公共互联网。该策略无法强制实现私有网络路由。  \n*   **\"部署AWS中转网关并将S3存储桶与SageMaker实例附加至网关\"**：S3存储桶属于全球服务，无法像VPC那样被\"附加\"到中转网关。中转网关用于VPC、VPN和直连网关之间的路由管理，不适用于为S3这类AWS公共服务提供私有访问通道。",
      "zhcn": ""
    },
    "answer": "AC",
    "o_id": "190"
  },
  {
    "id": "32",
    "question": {
      "enus": "A machine learning (ML) specialist at a retail company is forecasting sales for one of the company's stores. The ML specialist is using data from the past 10 years. The company has provided a dataset that includes the total amount of money in sales each day for the store. Approximately 5% of the days are missing sales data. The ML specialist builds a simple forecasting model with the dataset and discovers that the model performs poorly. The performance is poor around the time of seasonal events, when the model consistently predicts sales figures that are too low or too high. Which actions should the ML specialist take to try to improve the model's performance? (Choose two.) ",
      "zhcn": "某零售公司的机器学习专家正在为旗下门店进行销售额预测。该专家采用了过去十年的历史数据，公司提供的数据集包含该门店每日销售总额，其中约5%的日期存在销售数据缺失。专家基于此数据集构建了一个简易预测模型，但发现模型在季节性活动期间表现不佳——其预测值总是系统性偏离实际值，或明显偏高或偏低。若要提升模型性能，该专家应采取哪两项改进措施？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "向数据集中补充该店铺的销售周期信息。",
          "enus": "Add information about the store's sales periods to the dataset."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "邻近区域内各门店的销售数据汇总。",
          "enus": "Aggregate sales figures from stores in the same proximity."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "对数据进行平滑处理以修正季节性波动。",
          "enus": "Apply smoothing to correct for seasonal variation."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将预测频率由每日调整为每周。",
          "enus": "Change the forecast frequency from daily to weekly."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "采用线性插值法填补数据集中的缺失值。",
          "enus": "Replace missing values in the dataset by using linear interpolation."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案为：**\"汇总邻近门店的销售总额\"**与**\"采用线性插值法填补数据集中的缺失值\"**。\n\n**分析：**  \n模型表现不佳主要与季节性事件相关，说明其无法捕捉这些特殊时期的复杂规律。而5%的数据缺失进一步破坏了时间序列的连续性。  \n*   **汇总邻近门店的销售总额：** 这一操作能补充关键的环境数据。地理位置相近的门店往往受到类似的季节性因素影响（如节假日、当地天气）。通过引入这些数据，模型可以学习共通的季节性模式，从而提升在特殊时期对目标门店销售额的预测能力。  \n*   **采用线性插值法填补数据集中的缺失值：** 缺失值会扭曲模型对趋势的认知，尤其在时间序列中更为明显。线性插值法基于相邻日期的趋势估算缺失值，能为模型提供更完整连贯的数据集，且该方法简洁高效，特别适用于时间序列数据。\n\n**干扰项错误原因：**  \n*   **\"添加门店销售周期信息至数据集\"：** 该表述空泛无效。数据集已包含每日销售数据，销售周期信息本就存在。此方案未能提供可解释季节性波动的新特征（如促销活动或节假日信息）。  \n*   **\"应用平滑处理修正季节性波动\"：** 平滑处理（如移动平均法）是通过消除季节性和噪声来识别趋势的分析技术，并非提升预测模型的方法。若对训练数据实施平滑处理，反而会抹去模型需要学习的季节性信号，可能导致性能进一步下降。  \n*   **\"将预测频率从日度调整为周度\"：** 聚合为周度数据虽能平滑日常波动，却会损失数据粒度。这实为回避问题而非解决问题。模型无法捕捉季节性规律的核心矛盾依然存在（在周度层面可能更难建模），而改进要求明确针对日度预测模型。",
      "zhcn": ""
    },
    "answer": "BE",
    "o_id": "191"
  },
  {
    "id": "33",
    "question": {
      "enus": "A manufacturing company needs to identify returned smartphones that have been damaged by moisture. The company has an automated process that produces 2,000 diagnostic values for each phone. The database contains more than five million phone evaluations. The evaluation process is consistent, and there are no missing values in the data. A machine learning (ML) specialist has trained an Amazon SageMaker linear learner ML model to classify phones as moisture damaged or not moisture damaged by using all available features. The model's F1 score is 0.6. Which changes in model training would MOST likely improve the model's F1 score? (Choose two.) ",
      "zhcn": "一家制造公司需要甄别因受潮而损坏的退货智能手机。该公司采用自动化流程，为每部手机生成2000项诊断数据。数据库中已收录超过五百万次手机检测记录，评估流程标准统一，且数据无任何缺失。一位机器学习专家利用全部可用特征，训练了亚马逊SageMaker线性学习器模型，用以将手机划分为\"受潮损坏\"与\"未受潮损坏\"两类。当前模型的F1得分为0.6。若要提升该模型的F1得分，以下哪两项训练调整最可能见效？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "继续采用SageMaker线性学习器算法，同时运用SageMaker主成分分析（PCA）算法缩减特征变量数量。",
          "enus": "Continue to use the SageMaker linear learner algorithm. Reduce the number of features with the SageMaker principal component  analysis (PCA) algorithm."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "继续采用SageMaker线性学习器算法，同时通过scikit-learn多维缩放（MDS）算法减少特征数量。",
          "enus": "Continue to use the SageMaker linear learner algorithm. Reduce the number of features with the scikit-learn multi-dimensional scaling  (MDS) algorithm."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "继续采用SageMaker线性学习器算法，并将预测器类型设定为回归器。",
          "enus": "Continue to use the SageMaker linear learner algorithm. Set the predictor type to regressor."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "采用SageMaker平台的k-means算法，将聚类数k设为小于1000的值来训练模型。",
          "enus": "Use the SageMaker k-means algorithm with k of less than 1,000 to train the model."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "使用SageMaker k近邻（k-NN）算法进行模型训练时，请将降维目标设定在1,000以下。",
          "enus": "Use the SageMaker k-nearest neighbors (k-NN) algorithm. Set a dimension reduction target of less than 1,000 to train the model."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案为：  \n- **继续使用 SageMaker 线性学习器算法，并通过 SageMaker 主成分分析（PCA）算法减少特征数量。**  \n- **采用 SageMaker k-近邻（k-NN）算法，将降维目标设定为 1000 以下进行模型训练。**  \n\n**推导依据：**  \nF1 分数 0.6 表明线性学习器模型可能受维度灾难或无关特征噪声干扰。  \n- **PCA** 能在保留数据方差的前提下压缩特征空间，通过消除噪声提升模型表现。  \n- **k-NN** 对高维数据敏感，将维度降至 1000 以下（利用 SageMaker k-NN 内置的降维功能）可优化其性能。  \n\n**干扰项错误原因：**  \n- **scikit-learn 的 MDS** 无法扩展至 500 万条高维数据记录，对此数据量级 PCA 更具效率优势。  \n- **将预测器类型设为回归器** 不适用于分类场景（F1 是分类评估指标）。  \n- **k-means** 作为无监督算法不适用于分类任务，无法直接改善本场景中带标签数据的 F1 分数。",
      "zhcn": ""
    },
    "answer": "AE",
    "o_id": "199"
  },
  {
    "id": "34",
    "question": {
      "enus": "A company wants to deliver digital car management services to its customers. The company plans to analyze data to predict the likelihood of users changing cars. The company has 10 TB of data that is stored in an Amazon Redshift cluster. The company's data engineering team is using Amazon SageMaker Studio for data analysis and model development. Only a subset of the data is relevant for developing the machine learning models. The data engineering team needs a secure and cost-effective way to export the data to a data repository in Amazon S3 for model development. Which solutions will meet these requirements? (Choose two.) ",
      "zhcn": "一家公司希望为客户提供数字化汽车管理服务，并计划通过数据分析预测用户的换车可能性。该公司拥有10 TB数据存储于Amazon Redshift集群中，数据工程团队正使用Amazon SageMaker Studio进行数据分析与模型开发。由于仅需部分数据用于机器学习模型开发，该团队需要一种安全且经济高效的方式，将数据导出至Amazon S3的数据存储库以供模型开发。下列哪两种解决方案符合这些要求？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "在分布式SageMaker处理任务中启动多个中型计算实例。通过预构建的Apache Spark Docker镜像查询并绘制相关数据，同时将Amazon Redshift中的相关数据导出至Amazon S3存储空间。",
          "enus": "Launch multiple medium-sized instances in a distributed SageMaker Processing job. Use the prebuilt Docker images for Apache Spark  to query and plot the relevant data and to export the relevant data from Amazon Redshift to Amazon S3."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "以分布式模式启动多个中等规格的PySpark内核笔记本实例。从Amazon Redshift将数据下载至笔记本集群，对相关数据进行查询分析与可视化制图，最终将筛选后的数据从笔记本集群导出至Amazon S3存储空间。",
          "enus": "Launch multiple medium-sized notebook instances with a PySpark kernel in distributed mode. Download the data from Amazon Redshift  to the notebook cluster. Query and plot the relevant data. Export the relevant data from the notebook cluster to Amazon S3."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "借助AWS Secrets Manager妥善保管Amazon Redshift访问凭证。通过SageMaker Studio笔记本，调用已存储的认证信息，利用Python适配器建立与Amazon Redshift的安全连接。随后通过Python客户端执行数据查询，并将所需数据从Amazon Redshift导出至Amazon S3存储空间。",
          "enus": "Use AWS Secrets Manager to store the Amazon Redshift credentials. From a SageMaker Studio notebook, use the stored credentials to  connect to Amazon Redshift with a Python adapter. Use the Python client to query the relevant data and to export the relevant data from  Amazon Redshift to Amazon S3."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "运用AWS密钥管理服务存储Amazon Redshift的访问凭证。启动一个SageMaker超大型笔记本实例，并配置略大于10TB的块存储容量。通过Python连接器调用已存储的密钥建立与Amazon Redshift的连接，完成数据的下载、查询及可视化分析。最终将处理后的有效数据从本地笔记本驱动器导出至Amazon S3存储服务。",
          "enus": "Use AWS Secrets Manager to store the Amazon Redshift credentials. Launch a SageMaker extra-large notebook instance with block  storage that is slightly larger than 10 TB. Use the stored credentials to connect to Amazon Redshift with a Python adapter. Download,  query, and plot the relevant data. Export the relevant data from the local notebook drive to Amazon S3."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "使用SageMaker Data Wrangler查询并绘制相关数据，同时将Amazon Redshift中的相关数据导出至Amazon S3。",
          "enus": "Use SageMaker Data Wrangler to query and plot the relevant data and to export the relevant data from Amazon Redshift to Amazon S3."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案为前两个选项，因为它们提供了安全、可扩展且经济高效的方法，能够仅将亚马逊Redshift中的部分数据导出至亚马逊S3。  \n\n**正确答案一：** 使用预置Spark镜像的分布式SageMaker处理作业是高效方案，它通过多实例并行扩展处理海量数据，避免不必要地移动全部10TB数据，并直接将结果写入S3。  \n\n**正确答案二：** 通过Secrets管理器管理凭证，在SageMaker Studio笔记本中使用Python适配器直接查询Redshift，该方案安全且经济，仅提取所需数据而无需在本地下载完整数据集。  \n\n**错误选项排除原因：**  \n- **错误一：** 将10TB数据全部下载至笔记本集群既不符合成本效益，也会受存储和网络限制影响实操性。  \n- **错误二：** 选用本地存储超过10TB的超大型笔记本方案成本极高，且在仅需部分数据时显得多余。  \n- **错误三：** 单靠SageMaker Data Wrangler无法原生支持此规模下的Redshift至S3直接导出，它更侧重于数据准备与分析，而非批量导出操作。  \n\n核心原则在于避免全量数据传输，充分利用可扩展的无服务器或分布式方法进行数据子集提取。",
      "zhcn": ""
    },
    "answer": "AC",
    "o_id": "206"
  },
  {
    "id": "35",
    "question": {
      "enus": "A sports broadcasting company is planning to introduce subtitles in multiple languages for a live broadcast. The commentary is in English. The company needs the transcriptions to appear on screen in French or Spanish, depending on the broadcasting country. The transcriptions must be able to capture domain-specific terminology, names, and locations based on the commentary context. The company needs a solution that can support options to provide tuning data. Which combination of AWS services and features will meet these requirements with the LEAST operational overhead? (Choose two.) ",
      "zhcn": "一家体育转播公司计划为直播节目引入多语言字幕服务。其解说词为英文内容，需根据播出国家在屏幕上显示法语或西班牙语字幕。译文必须能够准确捕捉基于解说语境的领域专有术语、人名及地名。该公司需要一套支持提供调优数据选项的解决方案。以下哪两种AWS服务与功能的组合能以最小运维投入满足上述需求？（请选择两项。）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "亚马逊Transcribe自定义词汇增强版",
          "enus": "Amazon Transcribe with custom vocabularies"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "借助定制语言模型的亚马逊转录服务",
          "enus": "Amazon Transcribe with custom language models"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "Amazon SageMaker Seq2Seq",
          "enus": "Amazon SageMaker Seq2Seq"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "Amazon SageMaker 与 Hugging Face Speech2Text 的深度融合",
          "enus": "Amazon SageMaker with Hugging Face Speech2Text"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "亚马逊翻译",
          "enus": "Amazon Translate"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案是 **Amazon Transcribe with custom language models** 与 **Amazon Translate**。\n\n**解析：**  \n核心需求是将英文体育赛事直播解说转换为精准、实时的法语或西班牙语字幕。这一过程分为两个步骤：首先将语音转为文本（语音识别），随后将文本翻译为目标语言。\n\n*   **Amazon Transcribe with custom language models** 是第一步的理想选择。定制语言模型专为提升特定领域词汇的识别准确率而设计，尤其适用于包含专业术语、运动员姓名、场地名称等独特词汇的体育解说。该模型可根据您提供的数据进行训练优化，且作为托管服务，能最大程度减少运维负担。\n*   **Amazon Translate** 则适用于第二步。作为全托管式服务，它能实现英语至法语、西班牙语等语言的实时文本翻译，无需基础设施管理，完全符合“最低运维负担”的要求。\n\n**其他选项错误原因：**  \n*   **Amazon Transcribe with custom vocabularies（自定义词表）**：虽然自定义词表能辅助识别特定词汇，但其效果远不及完整的**定制语言模型**。自定义词表仅是关键词列表，而定制语言模型通过机器学习理解上下文语境，对于捕捉直播解说中灵活多变的复杂内容更为有效。\n*   **Amazon SageMaker Seq2Seq / 搭载Hugging Face Speech2Text的Amazon SageMaker**：这些方案需在Amazon SageMaker上构建、训练并部署定制机器学习模型。这将带来显著的运维负担，包括基础设施管理、模型训练及直播所需的扩展性与可靠性保障，明显违背“最低运维负担”的要求。此时，采用AWS专为场景构建的托管服务（Transcribe与Translate）才是恰当选择。\n\n**常见误区：** 主要误区在于当问题可通过组合AWS托管AI服务解决时，却选择了操作更复杂、定制性更强的工具（如SageMaker）。题目明确要求选择运维负担最轻的解决方案，这直接指向无需服务器管理、支持定制数据优化的预训练服务。",
      "zhcn": ""
    },
    "answer": "BE",
    "o_id": "215"
  },
  {
    "id": "36",
    "question": {
      "enus": "A data scientist at a financial services company used Amazon SageMaker to train and deploy a model that predicts loan defaults. The model analyzes new loan applications and predicts the risk of loan default. To train the model, the data scientist manually extracted loan data from a database. The data scientist performed the model training and deployment steps in a Jupyter notebook that is hosted on SageMaker Studio notebooks. The model's prediction accuracy is decreasing over time. Which combination of steps is the MOST operationally eficient way for the data scientist to maintain the model's accuracy? (Choose two.) ",
      "zhcn": "某金融服务公司的数据科学家利用Amazon SageMaker训练并部署了一套贷款违约预测模型。该模型通过分析新增贷款申请来预判违约风险。在模型训练阶段，这位数据科学家曾手动从数据库提取贷款数据，并在SageMaker Studio notebooks托管的Jupyter笔记本中完成了模型训练与部署操作。目前该模型的预测准确率正随时间推移逐渐下降。请问下列哪两项措施组合最能帮助数据科学家以最高运维效率维持模型准确率？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "运用SageMaker Pipelines构建自动化工作流，实现数据动态提取、模型训练及新版模型的无缝部署。",
          "enus": "Use SageMaker Pipelines to create an automated workfiow that extracts fresh data, trains the model, and deploys a new version of the  model."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "配置SageMaker模型监控器时需设定精度阈值以检测模型漂移。当数据超出阈值范围时，将触发Amazon CloudWatch告警。通过将SageMaker Pipelines工作流与CloudWatch告警关联，即可在监测到异常时自动启动模型重训练流程。",
          "enus": "Configure SageMaker Model Monitor with an accuracy threshold to check for model drift. Initiate an Amazon CloudWatch alarm when  the threshold is exceeded. Connect the workfiow in SageMaker Pipelines with the CloudWatch alarm to automatically initiate retraining."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "将模型预测结果存储于Amazon S3。创建每日运行的SageMaker处理作业，该作业从Amazon S3读取预测数据，检测模型预测准确率的变化，并在发现显著波动时发送邮件通知。",
          "enus": "Store the model predictions in Amazon S3. Create a daily SageMaker Processing job that reads the predictions from Amazon S3, checks  for changes in model prediction accuracy, and sends an email notification if a significant change is detected."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "请在SageMaker Studio notebooks托管的Jupyter笔记本中重新运行相关步骤，以重新训练模型并部署新版模型。",
          "enus": "Rerun the steps in the Jupyter notebook that is hosted on SageMaker Studio notebooks to retrain the model and redeploy a new version  of the model."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将训练与部署代码从SageMaker Studio笔记本导出为Python脚本，并将其封装为亚马逊弹性容器服务（Amazon ECS）任务，以便通过AWS Lambda函数触发执行。",
          "enus": "Export the training and deployment code from the SageMaker Studio notebooks into a Python script. Package the script into an Amazon  Elastic Container Service (Amazon ECS) task that an AWS Lambda function can initiate."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "**正确答案如下：**  \n1. **配置 SageMaker Model Monitor 并设定准确度阈值以检测模型漂移。当超出阈值时，触发 Amazon CloudWatch 警报。通过 SageMaker Pipelines 将工作流与 CloudWatch 警报关联，从而自动启动模型重训练。**  \n2. **将模型预测结果存储于 Amazon S3。创建每日运行的 SageMaker Processing 作业，从 Amazon S3 读取预测数据并检测模型准确度变化，若发现显著波动则自动发送邮件通知。**  \n\n---  \n### 设计逻辑  \n题目要求找到**运营效率最优**的方案来维持模型准确度，已知当前模型因漂移导致性能随时间下降。  \n- **正确答案 1** 的合理性在于：通过**自动化监控（Model Monitor）** 检测模型漂移，在准确度下降时触发 **CloudWatch 警报**，并利用 **SageMaker Pipelines 自动启动重训练**。此方案高效性体现在最大限度减少人工干预，并能快速响应模型性能退化。  \n- **正确答案 2** 的合理性在于：将预测数据存储于 S3 后，通过**每日定时运行的 SageMaker Processing 作业**自动检测准确度变化并邮件通知。该方法通过系统化定期检查避免了手动操作，兼顾效率与稳定性。  \n\n---  \n### 错误选项辨析  \n- **错误选项 1**（按固定周期用 SageMaker Pipelines 自动抽取数据、训练并部署）效率较低，因其**无论模型是否漂移都会执行重训练**，若无需更新则造成资源浪费。  \n- **错误选项 2**（在 Jupyter Notebook 中手动重复执行流程）**不符合运营效率要求**，依赖人工操作不仅速度慢、易出错，且难以规模化。  \n- **错误选项 3**（将代码部署至由 Lambda 触发的 ECS 任务）脱离了 SageMaker 原生的 MLOps 工具链，引入不必要的复杂度，运维成本显著高于使用 SageMaker 内置服务。  \n\n---  \n### 核心结论  \n本题中的“运营效率”关键在于：**通过自动化手段检测准确度下降**，并**仅在必要时触发重训练**，而非依赖固定周期或人工干预。正确答案通过 SageMaker 集成的监控与管道自动化功能实现了这一目标。",
      "zhcn": ""
    },
    "answer": "BC",
    "o_id": "222"
  },
  {
    "id": "37",
    "question": {
      "enus": "A retail company wants to create a system that can predict sales based on the price of an item. A machine learning (ML) engineer built an initial linear model that resulted in the following residual plot: Which actions should the ML engineer take to improve the accuracy of the predictions in the next phase of model building? (Choose three.) ",
      "zhcn": "一家零售企业计划构建一套能够根据商品价格预测销量的系统。机器学习工程师初步建立的线性模型生成了如下残差图：在模型构建的下一阶段，该工程师应采取哪三项措施来提升预测精准度？（请选择三项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "将数据进行均匀降采样，以减少数据量。",
          "enus": "Downsample the data uniformly to reduce the amount of data."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "为数据的不同部分建立两种不同的模型。",
          "enus": "Create two different models for different sections of the data."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "在价格低于50的数据区间内进行降采样处理。",
          "enus": "Downsample the data in sections where Price < 50."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "当价格高于50时，将输入数据偏移一个固定值。",
          "enus": "Offset the input data by a constant value where Price > 50."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "在审视输入数据时，若遇合适情形，应采用非线性转换方法加以处理。",
          "enus": "Examine the input data, and apply non-linear data transformations where appropriate."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "采用非线性模型替代线性模型。",
          "enus": "Use a non-linear model instead of a linear model."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "**正确答案为：** **\"对数据进行均匀降采样以减少数据量\"**、**\"对价格低于50的数据区段进行降采样\"**，以及**\"检查输入数据，并酌情应用非线性数据变换\"**。\n\n**分析：**\n残差图显示出明显规律：当价格较低时（价格 < 50），残差的方差非常大（数据点零散分布在零线上下）；而当价格较高时（价格 > 50），方差则非常小（数据点紧密聚集）。这违背了线性回归中同方差性（误差方差恒定）的基本假设。\n\n*   **有效解决方案：**\n    *   **降采样（均匀或在低价区进行）：** 核心问题在于方差异常。通过减少低价、高方差区域的数据点数量，可以降低模型受噪声数据的影响，从而更有效地捕捉整体趋势。\n    *   **应用非线性变换：** 残差图的漏斗形态暗示价格与销量之间可能并非纯线性关系。对输入数据进行变换（例如使用价格的对数），有助于稳定方差，并可能揭示更接近线性的关系。\n\n*   **无效方案辨析：**\n    *   **\"建立两个独立模型...\"**：此法看似合理，实则过度复杂。问题的本质是方差问题和潜在的非线性关系，完全可以通过数据变换和正则化/降采样来解决。构建独立模型只会徒增复杂度。\n    *   **\"对输入数据进行偏移调整...\"**：此类操作（如添加常数）无法解决异方差性这一核心问题。它仅会平移数据，既无法修正方差问题，也无法改善函数关系形式。\n    *   **\"采用非线性模型...\"**：此为**干扰项**。非线性模型或许有效，但本题明确要求的是在下一建模阶段可采取的措施。首要步骤应是诊断并修复数据问题（降采样、变换），而非直接转向完全不同的模型架构。关于数据变换的方案，正是处理非线性问题时更为具体和稳妥的步骤。\n\n**关键误区：** 主要误区在于未能优先诊断并修复残差图所揭示的明显数据问题（异方差性），而急于改变模型类型。上述有效方案直指数据方差这一核心矛盾。",
      "zhcn": ""
    },
    "answer": "ACE",
    "o_id": "223"
  },
  {
    "id": "38",
    "question": {
      "enus": "A company has hired a data scientist to create a loan risk model. The dataset contains loan amounts and variables such as loan type, region, and other demographic variables. The data scientist wants to use Amazon SageMaker to test bias regarding the loan amount distribution with respect to some of these categorical variables. Which pretraining bias metrics should the data scientist use to check the bias distribution? (Choose three.) ",
      "zhcn": "某公司聘请一位数据科学家构建贷款风险模型。数据集包含贷款金额及贷款类型、地区与其他人口统计变量。该数据科学家计划使用Amazon SageMaker检验贷款金额分布在部分分类变量上的偏差。请问其应选用哪三项预训练偏差指标来评估偏差分布？"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "类别失衡",
          "enus": "Class imbalance"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "条件性人口差异",
          "enus": "Conditional demographic disparity"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "标签比例差异",
          "enus": "Difference in proportions of labels"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "詹森-香农散度",
          "enus": "Jensen-Shannon divergence"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "Kullback-Leieber散度",
          "enus": "Kullback-Leibler divergence"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "“全变差距离”",
          "enus": "Total variation distance"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案为**Class Imbalance**（类别不平衡）、**Difference in Proportions of Labels**（标签比例差异）和**Total Variation Distance**（总变差距离）。**类别不平衡**用于衡量数据集中某类样本是否过度集中，这种偏差可能导致模型预测失真。**标签比例差异**通过比较不同群体中特定结果（如贷款批准/拒绝）的比例，以识别差异性影响。**总变差距离**则能量化两个概率分布之间的差异，适用于比较不同类别间的贷款金额分布。\n\n而被列为干扰项的**Conditional Demographic Disparity**（条件人口统计差异）、**Jensen-Shannon Divergence**（詹森-香农散度）与**Kullback-Leibler Divergence**（KL散度），更适用于*训练后*的公平性评估或模型预测偏差分析，而非*训练前*的数据分布偏差检测。若在此阶段误用这些指标，相当于将本应针对模型输出的度量工具错误地应用于仅需检验数据集特征的场景。",
      "zhcn": ""
    },
    "answer": "ACF",
    "o_id": "227"
  },
  {
    "id": "39",
    "question": {
      "enus": "An online retail company wants to develop a natural language processing (NLP) model to improve customer service. A machine learning (ML) specialist is setting up distributed training of a Bidirectional Encoder Representations from Transformers (BERT) model on Amazon SageMaker. SageMaker will use eight compute instances for the distributed training. The ML specialist wants to ensure the security of the data during the distributed training. The data is stored in an Amazon S3 bucket. Which combination of steps should the ML specialist take to protect the data during the distributed training? (Choose three.) ",
      "zhcn": "一家网络零售公司计划开发自然语言处理模型以提升客户服务质量。一位机器学习专家正在亚马逊SageMaker平台上配置双向Transformer编码器模型的分布式训练任务。该训练将启用八个计算实例。为确保分布式训练期间的数据安全（训练数据存储于亚马逊S3存储桶中），机器学习专家应采取哪三项组合措施？（请选择三项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "在私有虚拟私有云中运行分布式训练任务，并启用容器间通信加密功能。",
          "enus": "Run distributed training jobs in a private VPC. Enable inter-container trafic encryption."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "在多个虚拟私有云中运行分布式训练任务。启用虚拟私有云对等互联。",
          "enus": "Run distributed training jobs across multiple VPCs. Enable VPC peering."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "创建S3 VPC终端节点，随后配置网络路由策略、终端节点策略及S3存储桶策略。",
          "enus": "Create an S3 VPC endpoint. Then configure network routes, endpoint policies, and S3 bucket policies."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "通过使用IAM角色，授予对SageMaker资源的只读访问权限。",
          "enus": "Grant read-only access to SageMaker resources by using an IAM role."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "创建一台NAT网关，并为该网关分配弹性IP地址。",
          "enus": "Create a NAT gateway. Assign an Elastic IP address for the NAT gateway."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "配置入站规则，允许来自与训练实例关联的安全组的流量通过。",
          "enus": "Configure an inbound rule to allow trafic from a security group that is associated with the training instances."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "在分布式训练过程中保护数据的正确步骤组合如下：\n\n1. **在私有VPC中运行分布式训练任务，并启用容器间流量加密**\n2. **创建S3 VPC端点，随后配置网络路由、端点策略及S3存储桶策略**\n3. **通过IAM角色授予对SageMaker资源的只读访问权限**\n\n**技术解析：**\n- **私有VPC+容器间流量加密** 可确保训练实例与公共互联网隔离，且实例间传输的数据均经过加密处理\n- **S3 VPC端点** 能够在VPC与S3之间建立安全私有连接，避免流量经过公共互联网，保证数据传输始终在AWS网络内部完成\n- **具备S3只读权限的IAM角色** 遵循最小权限原则，有效防止对数据的意外修改\n\n**其他选项的谬误所在：**\n- **\"跨多个VPC运行分布式训练任务并启用VPC对等连接\"** → 方案过于复杂且无必要，单一私有VPC已能提供更安全的隔离环境\n- **\"创建NAT网关并分配弹性IP地址\"** → NAT网关用于私有子网的出站互联网访问，而本场景通过VPC端点可完全避免暴露至互联网\n- **\"配置允许来自训练实例关联安全组的流量入站规则\"** → 此表述模糊且非核心数据保护措施，安全组应精确限制访问权限，而非无条件开放内部流量\n\n正确答案的核心逻辑在于**网络隔离（私有VPC）、传输加密（容器间加密、VPC端点）和最小权限原则（IAM角色）**——这三点正是AWS分布式训练场景下的安全最佳实践。",
      "zhcn": ""
    },
    "answer": "BEF",
    "o_id": "229"
  },
  {
    "id": "40",
    "question": {
      "enus": "An ecommerce company is collecting structured data and unstructured data from its website, mobile apps, and IoT devices. The data is stored in several databases and Amazon S3 buckets. The company is implementing a scalable repository to store structured data and unstructured data. The company must implement a solution that provides a central data catalog, self-service access to the data, and granular data access policies and encryption to protect the data. Which combination of actions will meet these requirements with the LEAST amount of setup? (Choose three.) ",
      "zhcn": "一家电商企业正从其官方网站、移动应用及物联网设备中采集结构化与非结构化数据。这些数据目前存储于多个数据库及亚马逊S3存储桶中。该公司正在构建一个可扩展的数据存储库，用以统一存储两类数据。此方案需实现三大核心功能：建立统一数据目录、提供自助式数据查询服务、实施细粒度数据访问策略及加密保护机制。请问以下哪三项措施的组合能以最简配置满足上述需求？（请选择三项答案）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "梳理数据库及S3存储桶中的现有数据，并将其接入AWS Lake Formation管理体系。",
          "enus": "Identify the existing data in the databases and S3 buckets. Link the data to AWS Lake Formation."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "梳理数据库与S3存储桶中的现有数据，并将其关联至AWS Glue服务。",
          "enus": "Identify the existing data in the databases and S3 buckets. Link the data to AWS Glue."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "对关联数据源运行AWS Glue爬虫程序，以构建统一的数据目录。",
          "enus": "Run AWS Glue crawlers on the linked data sources to create a central data catalog."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "通过AWS身份与访问管理服务（IAM）实施精细化权限管控，并为每个数据源配置服务器端加密方案。",
          "enus": "Apply granular access policies by using AWS Identity and Access Management (1AM). Configure server-side encryption on each data  source."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "借助AWS Lake Formation实施精细化的访问权限管控与数据加密机制。",
          "enus": "Apply granular access policies and encryption by using AWS Lake Formation."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "借助AWS Glue实施精细化的访问策略与数据加密方案。",
          "enus": "Apply granular access policies and encryption by using AWS Glue."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "为以最简配置满足需求，应采取以下操作组合：  \n1. **识别数据库及S3存储桶中的现有数据，并将其关联至AWS Lake Formation**  \n2. **通过AWS身份与访问管理（IAM）实施精细访问策略，并为各数据源配置服务端加密**  \n3. **通过AWS Lake Formation实施精细访问策略与加密配置**  \n\n### 方案解析：  \n本题要求实现**集中式数据目录**、**自助式数据访问**及**精细化数据访问策略与加密**，同时强调最小化配置量。AWS Lake Formation正是为此设计——它在AWS Glue数据目录基础上，整合了简化的数据治理、访问控制与加密管理功能。  \n\n- **Lake Formation与Glue的差异**：  \n  Lake Formation能自动部署安全数据湖，包括（底层通过Glue爬虫程序实现的）数据目录构建及统一访问控制。直接选用Lake Formation（正确选项）比手动配置Glue爬虫与安全模块（错误选项）更为简化，后者需额外投入配置工作。  \n\n- **访问策略与加密的实施**：  \n  通过Lake Formation集中管理策略与加密（正确选项），相比为每个数据源单独配置IAM策略和服务端加密（虽然后者仍属有效方案）更为高效。错误选项中建议通过AWS Glue管理访问策略并不成立，因Glue本身不支持表/列级精细权限控制——该功能由Lake Formation提供。  \n\n- **错误选项的症结**：  \n    - “将数据关联至AWS Glue”忽略了Lake Formation的数据治理特性；  \n    - “运行AWS Glue爬虫…”属于冗余操作，因Lake Formation在关联数据源时会自动调用Glue爬虫；  \n    - “通过AWS Glue实施精细访问策略与加密”表述有误——Glue原生不支持精细权限策略，该功能实由Lake Formation实现。  \n\n综上，正确答案通过充分发挥Lake Formation的集成能力，避免了手动组合Glue与IAM组件的复杂性，真正实现了最小化配置的目标。",
      "zhcn": ""
    },
    "answer": "ADE",
    "o_id": "231"
  },
  {
    "id": "41",
    "question": {
      "enus": "A machine learning (ML) specialist is developing a deep learning sentiment analysis model that is based on data from movie reviews. After the ML specialist trains the model and reviews the model results on the validation set, the ML specialist discovers that the model is overfitting. Which solutions will MOST improve the model generalization and reduce overfitting? (Choose three.) ",
      "zhcn": "一位机器学习专家正在开发一款基于影评数据的深度学习情感分析模型。在完成模型训练并验证验证集结果后，该专家发现模型存在过拟合现象。下列哪三项措施最能有效提升模型泛化能力并抑制过拟合？（请选择三项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "以不同随机种子打乱数据集。",
          "enus": "Shufie the dataset with a different seed."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "降低学习速率。",
          "enus": "Decrease the learning rate."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "增加网络层数。",
          "enus": "Increase the number of layers in the network."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "加入L1正则化与L2正则化。",
          "enus": "Add L1 regularization and L2 regularization."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "加入随机失活层。",
          "enus": "Add dropout."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "减少网络层数。",
          "enus": "Decrease the number of layers in the network."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案为：**\"引入随机失活（dropout）\"**、**\"减少网络层数\"** 以及 **\"添加L1与L2正则化\"**。  \n**解析：**  \n过拟合指模型过度学习训练数据（包括噪声）而导致泛化能力下降的现象。针对该问题的直接解决方案包括：  \n- **引入随机失活**：通过在训练中随机禁用神经元，避免网络对特定节点产生依赖，从而提升泛化能力。  \n- **减少网络层数**：简化模型结构可降低其学习训练数据中复杂噪声的可能性。  \n- **添加L1与L2正则化**：通过对权重施加惩罚机制，促使模型学习更简洁、通用的规律。  \n\n**其余选项错误原因：**  \n- **\"增加网络层数\"**：模型复杂化反而可能加剧过拟合。  \n- **\"采用不同随机种子打乱数据集\"**：虽属良好实践，但若数据分布不变则无法解决过拟合。  \n- **\"降低学习率\"**：此举影响收敛速度，并非直接针对过拟合的改进措施，反而可能因训练轮次增加而放大过拟合风险。  \n\n关键在于选择能显式简化模型或引入约束以增强泛化能力的技术。",
      "zhcn": ""
    },
    "answer": "CEF",
    "o_id": "232"
  },
  {
    "id": "42",
    "question": {
      "enus": "A company’s data scientist has trained a new machine learning model that performs better on test data than the company’s existing model performs in the production environment. The data scientist wants to replace the existing model that runs on an Amazon SageMaker endpoint in the production environment. However, the company is concerned that the new model might not work well on the production environment data. The data scientist needs to perform A/B testing in the production environment to evaluate whether the new model performs well on production environment data. Which combination of steps must the data scientist take to perform the A/B testing? (Choose two.) ",
      "zhcn": "某公司的数据科学家训练出一款新的机器学习模型，其在测试数据上的表现优于公司生产环境中现有的模型。该数据科学家希望替换当前在生产环境中通过Amazon SageMaker端点运行的模型。然而公司担心新模型可能无法很好地适应生产环境的数据。数据科学家需要在生产环境中进行A/B测试，以评估新模型在实际生产数据上的表现。请问数据科学家必须采取哪两个步骤组合来完成此次A/B测试？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "创建一个新的端点配置，其中需包含针对两种模型各自的生产变体。",
          "enus": "Create a new endpoint configuration that includes a production variant for each of the two models."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "新建一个端点配置，其中包含指向不同端点的两种目标变体。",
          "enus": "Create a new endpoint configuration that includes two target variants that point to different endpoints."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将新模型部署至现有终端节点。",
          "enus": "Deploy the new model to the existing endpoint."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "更新现有端点以启用新模型。",
          "enus": "Update the existing endpoint to activate the new model."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "请将现有终端更新为采用新版终端配置。",
          "enus": "Update the existing endpoint to use the new endpoint configuration."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "**正确答案是：** **“创建包含两种模型生产变体的新终端节点配置”** 以及 **“更新现有终端节点以采用新配置”**。\n\n**核心理由：** 亚马逊 SageMaker 的 A/B 测试是通过创建一个包含多个生产变体（每个变体指向不同模型）的终端节点配置，然后更新现有终端节点以使用此新配置来实现的。这使终端节点能够在两个模型之间分配流量，以便比较其性能。\n\n-   第一个正确答案成立，因为您必须在同一个终端节点配置中将两个模型都定义为变体。\n-   第二个正确答案成立，因为您通过更新现有终端节点的配置来启动 A/B 测试，而无需部署单独的终端节点。\n\n**干扰项错误原因：**\n-   **“创建包含指向不同终端节点的两个目标变体的新配置”** 错误，因为 SageMaker 的 A/B 测试是在单个终端节点内使用变体，而非使用独立的终端节点。\n-   **“将新模型部署到现有终端节点”** 具有误导性——若不使用变体和新配置，无法直接将两个模型部署到同一终端节点。\n-   **“更新现有终端节点以激活新模型”** 表述过于模糊，并非 SageMaker 的准确方法；正确流程涉及终端节点配置的更新，而非简单地“激活”某个模型。\n\n**常见误区：** 误以为 A/B 测试需要独立的终端节点，或认为可以直接替换模型，而不是利用 SageMaker 内置的生产变体流量分配功能。",
      "zhcn": ""
    },
    "answer": "AC",
    "o_id": "247"
  },
  {
    "id": "43",
    "question": {
      "enus": "A data scientist wants to improve the fit of a machine learning (ML) model that predicts house prices. The data scientist makes a first attempt to fit the model, but the fitted model has poor accuracy on both the training dataset and the test dataset. Which steps must the data scientist take to improve model accuracy? (Choose three.) ",
      "zhcn": "一位数据科学家希望优化预测房价的机器学习模型拟合效果。初次尝试建模后，发现模型在训练集和测试集上的预测精度均不理想。为提升模型准确性，该数据科学家应采取以下哪三项措施？（请选择三项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "增强模型所使用的正则化强度。",
          "enus": "Increase the amount of regularization that the model uses."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "降低模型所使用的正则化强度。",
          "enus": "Decrease the amount of regularization that the model uses."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "增加模型训练所用的样本数量。",
          "enus": "Increase the number of training examples that that model uses."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "增加模型所用的测试样例数量。",
          "enus": "Increase the number of test examples that the model uses."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "提升模型所采用的特征数量。",
          "enus": "Increase the number of model features that the model uses."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "精简模型所使用的特征数量。",
          "enus": "Decrease the number of model features that the model uses."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案为：**减小正则化强度**、**增加测试样本数量**以及**减少模型特征数量**。  \n\n**解析：**  \n问题指出模型在*训练数据*和*测试数据*上均表现不佳，这表明存在**欠拟合**——模型过于简单，无法捕捉数据中的规律。  \n- **降低正则化强度**：正则化会抑制模型复杂度，减弱正则化可使模型更好地拟合训练数据，从而缓解欠拟合。  \n- **增加测试样本**：虽然这不能直接提升模型性能，但更多的测试数据能更准确地评估泛化误差，有助于客观衡量改进效果。  \n- **减少特征数量**：若部分特征无关紧要，剔除噪声特征可使模型聚焦于有效信号，从而改善欠拟合时的表现。  \n\n**干扰项错误原因：**  \n- *增强正则化*：这会使本已欠拟合的模型更加简单，导致性能进一步恶化。  \n- *增加训练样本*：欠拟合意味着模型已无法从现有数据中有效学习，在未提升模型能力的前提下增加数据并无助益。  \n- *增加特征数量*：若模型缺乏预测因子，添加特征可能有效；但此处更直接的解决方式是先降低正则化强度，盲目增加特征可能引发过拟合，却未解决欠拟合的核心问题。  \n\n关键在于认识到模型在训练集和测试集上均表现不佳指向欠拟合，因此应采取提升模型灵活性或降低噪声的措施。",
      "zhcn": ""
    },
    "answer": "BDF",
    "o_id": "254"
  },
  {
    "id": "44",
    "question": {
      "enus": "A company is creating an application to identify, count, and classify animal images that are uploaded to the company’s website. The company is using the Amazon SageMaker image classification algorithm with an ImageNetV2 convolutional neural network (CNN). The solution works well for most animal images but does not recognize many animal species that are less common. The company obtains 10,000 labeled images of less common animal species and stores the images in Amazon S3. A machine learning (ML) engineer needs to incorporate the images into the model by using Pipe mode in SageMaker. Which combination of steps should the ML engineer take to train the model? (Choose two.) ",
      "zhcn": "某公司正在开发一款应用程序，用于识别、计数和分类用户上传至其网站的动物图像。该公司采用亚马逊SageMaker图像分类算法，并搭配ImageNetV2卷积神经网络（CNN）架构。该解决方案对大多数常见动物图像识别效果良好，但对许多较为罕见的动物物种却难以辨识。公司现已获取一万张稀有动物物种的标注图像，并存储于亚马逊S3服务中。机器学习工程师需通过SageMaker的Pipe模式将这些图像数据整合到模型中。请问该工程师应采取哪两种步骤组合来完成模型训练？（请选择两项正确答案）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "采用ResNet架构。通过随机初始化网络权重，开启完整训练模式。",
          "enus": "Use a ResNet model. Initiate full training mode by initializing the network with random weights."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "采用SageMaker图像分类算法中提供的Inception模型进行实现。",
          "enus": "Use an Inception model that is available with the SageMaker image classification algorithm."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "创建一个包含图像文件及对应类别标签列表的.lst文件，并将该文件上传至Amazon S3存储空间。",
          "enus": "Create a .lst file that contains a list of image files and corresponding class labels. Upload the .lst file to Amazon S3."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "启动迁移学习。利用较为稀有物种的图像数据对模型进行训练。",
          "enus": "Initiate transfer learning. Train the model by using the images of less common species."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "采用JSON Lines格式的增强清单文件。",
          "enus": "Use an augmented manifest file in JSON Lines format."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案是 **“使用 SageMaker 图像分类算法提供的 Inception 模型”** 与 **“启动迁移学习，利用不常见物种的图像对模型进行训练”**。  \n**推理依据：** 题目指出现有模型对常见动物识别效果良好，但对稀有物种识别不佳。该公司已拥有基于 ImageNet 训练的 CNN 模型，因此最高效的方案是采用**迁移学习**——复用预训练模型（例如 SageMaker 内置图像分类算法中的 Inception 模型），并基于新标注的 1 万张稀有物种图像进行微调。此举既可避免从零开始训练，又能充分利用已习得的特征。  \n**干扰选项错误原因：**  \n- **“使用 ResNet 模型，通过随机初始化网络权重启动全训练模式”** → 在已有预训练模型的情况下，采用随机权重的完整训练既无必要也低效；相对于 ImageNet 规模的数据，1 万张图像属于小数据集，迁移学习才是标准做法。  \n- **“创建包含图像文件及对应类别标签的 .lst 文件，并将其上传至 Amazon S3”** → 虽然 .lst 文件在 SageMaker *文件模式* 的图像分类中可用，但本题明确要求**管道模式**，该模式需使用 RecordIO (.rec) 格式而非 .lst 文件。  \n- **“使用 JSON Lines 格式的增强清单文件”** → 增强清单 JSON 适用于 SageMaker Ground Truth 及部分内置算法，但 SageMaker 图像分类算法在管道模式下需使用 .lst + .rec 或纯 .rec 格式，不支持 JSON Lines。  \n综上，正确方案是组合使用内置模型（Inception）并基于新数据实施迁移学习。",
      "zhcn": ""
    },
    "answer": "BD",
    "o_id": "256"
  },
  {
    "id": "45",
    "question": {
      "enus": "A pharmaceutical company performs periodic audits of clinical trial sites to quickly resolve critical findings. The company stores audit documents in text format. Auditors have requested help from a data science team to quickly analyze the documents. The auditors need to discover the 10 main topics within the documents to prioritize and distribute the review work among the auditing team members. Documents that describe adverse events must receive the highest priority. A data scientist will use statistical modeling to discover abstract topics and to provide a list of the top words for each category to help the auditors assess the relevance of the topic. Which algorithms are best suited to this scenario? (Choose two.) ",
      "zhcn": "一家制药公司定期对临床试验基地开展审计，以便迅速处理关键发现。该公司以文本格式存储审计文件。审计人员请求数据科学团队协助快速分析这些文件，旨在从文档中识别十大核心主题，从而合理分配审计团队的审阅工作优先级。其中，描述不良事件的文档必须列为最高优先级别。数据科学家将采用统计建模方法挖掘抽象主题，并为每个类别提供核心词汇列表，以辅助审计人员评估主题相关性。请问下列哪种算法最适用于此场景？（请选择两项。）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "潜在狄利克雷分布（LDA）",
          "enus": "Latent Dirichlet allocation (LDA)"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "随机森林分类器",
          "enus": "Random forest classifier"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "神经主题建模（NTM）",
          "enus": "Neural topic modeling (NTM)"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "线性支持向量机",
          "enus": "Linear support vector machine"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "线性回归",
          "enus": "Linear regression"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "**问题分析：** 本任务需在无预定义标签的情况下（无监督学习）从文本文档中发掘抽象主题，并优先处理提及不良事件的文档。核心要点包括：  \n- *发掘主题* → 需要主题建模算法  \n- *不良事件优先级排序* → 需要分类器识别包含不良事件的文档  \n\n**可行方案解析：**  \n1. **神经主题模型（NTM）**——适用于无监督的文本主题发掘  \n2. **随机森林分类器**——可通过训练判断文档是否包含不良事件（监督任务）  \n\n**方案优势说明：**  \n- **NTM**作为现代主题建模方法，能提取语义连贯的主题并生成主题核心词表，符合\"发掘十大主题\"的要求  \n- **随机森林**在处理文本分类任务时（需结合TF-IDF等特征工程）表现优异，能有效标记高优先级不良事件文档  \n\n**其他方案局限性：**  \n- **潜在狄利克雷分布（LDA）**：虽是主题建模算法，但NTM作为更先进的神经网络方法更适合当前任务；LDA模型相对传统，处理复杂文本时能力有限  \n- **线性支持向量机**：虽可用于不良事件分类，但随机森林在处理不平衡数据或非线性文本特征时通常表现更优  \n- **线性回归**：不适用于分类或主题建模任务，仅适用于连续型结果预测  \n\n**常见误区提示：**  \n选择LDA而非NTM可能是由于LDA的知名度较高，但就现代文本分析而言，基于神经网络的NTM才是更合适的选择。",
      "zhcn": ""
    },
    "answer": "BC",
    "o_id": "263"
  },
  {
    "id": "46",
    "question": {
      "enus": "A machine learning (ML) specialist uploads 5 TB of data to an Amazon SageMaker Studio environment. The ML specialist performs initial data cleansing. Before the ML specialist begins to train a model, the ML specialist needs to create and view an analysis report that details potential bias in the uploaded data. Which combination of actions will meet these requirements with the LEAST operational overhead? (Choose two.) ",
      "zhcn": "一位机器学习专家将5 TB数据上传至Amazon SageMaker Studio环境，并完成了初步的数据清洗。在开始训练模型之前，该专家需生成并查阅一份分析报告，其中需详细说明所上传数据中可能存在的偏差。若要满足以上需求，同时尽可能降低运维负担，应选择哪两项操作组合？（请选出两项正确答案）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "利用SageMaker Clarify自动检测数据偏差。",
          "enus": "Use SageMaker Clarify to automatically detect data bias"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "在SageMaker Ground Truth中启用偏差检测功能，即可自动分析数据特征。",
          "enus": "Turn on the bias detection option in SageMaker Ground Truth to automatically analyze data features."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "利用SageMaker Model Monitor生成偏差漂移报告。",
          "enus": "Use SageMaker Model Monitor to generate a bias drift report."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "配置SageMaker Data Wrangler以生成偏差报告。",
          "enus": "Configure SageMaker Data Wrangler to generate a bias report."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "利用SageMaker Experiments进行数据校验。",
          "enus": "Use SageMaker Experiments to perform a data check"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案为 **\"使用 SageMaker Clarify 自动检测数据偏差\"** 与 **\"配置 SageMaker Data Wrangler 生成偏差报告\"**。SageMaker Clarify 专为在训练前自动识别数据集潜在偏差而设计，能以最小配置生成详尽报告；SageMaker Data Wrangler 则在数据准备流程中内置偏差检测功能，可快速完成分析与可视化。  \n其余选项不适用原因如下：  \n- **SageMaker Ground Truth** 用于数据标注，而非训练前的偏差分析；  \n- **SageMaker Model Monitor** 针对模型部署后的偏差漂移检测，不适用于训练前阶段；  \n- **SageMaker Experiments** 专注于追踪训练过程与超参数，与训练前数据偏差分析无关。  \n若选用这些选项，不仅需要额外操作步骤，还会因场景错配增加运维负担。",
      "zhcn": ""
    },
    "answer": "AD",
    "o_id": "272"
  },
  {
    "id": "47",
    "question": {
      "enus": "A machine learning (ML) engineer has created a feature repository in Amazon SageMaker Feature Store for the company. The company has AWS accounts for development, integration, and production. The company hosts a feature store in the development account. The company uses Amazon S3 buckets to store feature values ofiine. The company wants to share features and to allow the integration account and the production account to reuse the features that are in the feature repository. Which combination of steps will meet these requirements? (Choose two.) ",
      "zhcn": "一位机器学习工程师在公司内部的Amazon SageMaker特征存储中创建了一个特征库。该公司分别设有开发、集成和生产环境的AWS账户，其中特征存储部署于开发账户，并采用Amazon S3存储桶离线保存特征值。现需实现特征共享功能，使集成账户与生产账户能够复用特征库中的特征。下列哪两项步骤组合可满足此需求？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "在开发账户中创建一个IAM角色，供集成账户和生产账户担任。为该角色附加IAM策略，允许其访问特征存储库和S3存储桶。",
          "enus": "Create an IAM role in the development account that the integration account and production account can assume. Attach IAM policies to  the role that allow access to the feature repository and the S3 buckets."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "通过AWS资源访问管理器（AWS RAM），将开发账户中关联S3存储桶的特征库共享至集成账户与生产账户。",
          "enus": "Share the feature repository that is associated the S3 buckets from the development account to the integration account and the  production account by using AWS Resource Access Manager (AWS RAM)."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "使用集成账户和生产账户中的AWS安全令牌服务（AWS STS）获取开发环境的访问凭证。",
          "enus": "Use AWS Security Token Service (AWS STS) from the integration account and the production account to retrieve credentials for the  development account."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "在开发环境的S3存储桶与集成及生产环境的S3存储桶之间配置数据同步机制。",
          "enus": "Set up S3 replication between the development S3 buckets and the integration and production S3 buckets."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "在开发账户中为 SageMaker 创建 AWS PrivateLink 端点。",
          "enus": "Create an AWS PrivateLink endpoint in the development account for SageMaker."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案如下：\n\n1.  **在开发账户中创建一个可供集成与生产账户委托的IAM角色，并为该角色附加允许访问特征仓库及S3存储桶的IAM策略。**\n2.  **建立开发环境S3存储桶至集成与生产环境S3存储桶的数据复制机制。**\n\n### 解析\n核心需求是将存储在SageMaker特征仓库（及其底层S3数据）中的特征从中心开发账户共享至其他AWS账户（集成与生产环境）。这是典型的AWS跨账户访问场景。\n\n**正确答案的核心优势：**\n\n*   **支持跨账户委托的IAM角色**：这是实现AWS跨账户访问的基础安全范式。开发账户创建允许其他账户委托的IAM角色，通过附加策略授予访问特征仓库API和离线S3数据所需的权限（如`sagemaker:GetRecord`、`s3:GetObject`）。这种方式既能实现精细化的权限控制，又具备可审计性。\n*   **S3跨区域复制**：SageMaker特征仓库会将特征值写入S3离线存储。通过将开发账户的S3存储桶复制至其他账户，既能保障集成与生产环境获得可靠的低延迟数据访问，又能实现数据访问与中心账户的解耦，既减轻了中心账户负载，又提供了本地化数据访问能力。\n\n**错误方案的缺陷分析：**\n\n*   **AWS资源访问管理器（RAM）**：该服务仅适用于共享子网或中转网关等特定AWS资源，**但无法支持共享SageMaker特征仓库或其关联的S3存储桶**。这是常见认知误区——误认为RAM可共享任意类型的云资源。\n*   **通过AWS安全令牌服务获取开发账户凭证**：STS服务本身是为角色委托提供临时凭证的正确技术基础。但此方案提议直接获取开发账户的凭证，既不符合标准操作规范，也存在安全隐患。跨账户访问应通过角色委托实现，而非直接使用账户根凭证或IAM用户凭证。\n*   **为SageMaker配置AWS PrivateLink**：该服务通过创建私有网络终端节点实现服务访问，能有效隔离公网流量。虽然适用于提升VPC连接安全性，但**无法解决跨账户权限管理问题**。集成与生产账户仍需通过IAM权限策略获取特征仓库访问权，而该方案未涉及任何授权配置，仅解决了网络层面的问题。\n\n注：专有名词（如IAM、S3、SageMaker Feature Store等）遵循技术文档惯例保留英文原称。",
      "zhcn": ""
    },
    "answer": "AD",
    "o_id": "275"
  },
  {
    "id": "48",
    "question": {
      "enus": "A company's machine learning (ML) specialist is building a computer vision model to classify 10 different trafic signs. The company has stored 100 images of each class in Amazon S3, and the company has another 10,000 unlabeled images. All the images come from dash cameras and are a size of 224 pixels × 224 pixels. After several training runs, the model is overfitting on the training data. Which actions should the ML specialist take to address this problem? (Choose two.) ",
      "zhcn": "某公司的机器学习专家正在构建一个计算机视觉模型，旨在对10种不同的交通标志进行分类。该公司已将每个类别的100张图像存储于Amazon S3中，同时还有10,000张未标注的图像。所有图像均采集自行车记录仪，尺寸为224像素×224像素。经过多次训练后，模型在训练数据上出现了过拟合现象。机器学习专家应采取哪两项措施来解决此问题？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "利用Amazon SageMaker Ground Truth对未标注图像进行智能标记。",
          "enus": "Use Amazon SageMaker Ground Truth to label the unlabeled images."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "运用图像预处理技术将图片转换为灰度图像。",
          "enus": "Use image preprocessing to transform the images into grayscale images."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "对标注图像进行旋转与平移的数据增强处理。",
          "enus": "Use data augmentation to rotate and translate the labeled images."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将最后一层的激活函数替换为S形函数。",
          "enus": "Replace the activation of the last layer with a sigmoid."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "利用亚马逊SageMaker平台的k近邻（k-NN）算法，对未标注图像进行智能分类。",
          "enus": "Use the Amazon SageMaker k-nearest neighbors (k-NN) algorithm to label the unlabeled images."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "**正确答案是**\"对已标注图像进行数据增强，通过旋转和平移变换扩充数据集\"**以及**\"利用Amazon SageMaker Ground Truth对未标注图像进行标注\"**。**\n\n**问题分析：**\n核心问题在于模型在少量标注数据（1,000张图像）上出现了过拟合。最佳解决思路是提升训练数据的规模与多样性。\n\n*   **正确答案一：\"对已标注图像进行数据增强，通过旋转和平移变换扩充数据集。\"** 此方法通过人为扩展训练数据集直接应对过拟合。通过对现有标注图像进行变换（如旋转、平移等），模型能够学习到更具鲁棒性的特征，而非简单记忆训练集。这是计算机视觉领域中一项标准且高效的技术。\n*   **正确答案二：\"利用Amazon SageMaker Ground Truth对未标注图像进行标注。\"** 这是最根本的解决方案。10,000张未标注图像是极具价值的潜在资源。借助Ground Truth为其准确添加标注并加入训练集，将极大增加数据量，为模型提供更多学习样本，从而从根源上缓解过拟合。\n\n**其他选项错误原因：**\n\n*   **错误选项：\"将最后一层激活函数替换为S型函数（sigmoid）。\"** S型函数通常用于二分类问题。针对十分类任务，最后一层正确的激活函数应为Softmax。改用S型函数本身即为错误，且无法解决过拟合问题。\n*   **错误选项：\"使用Amazon SageMaker k近邻（k-NN）算法为未标注图像添加标签。\"** k-NN模型是一种简单的基于实例的学习器。用它自动标注图像极易产生大量错误标签（噪声），若将这些噪声数据加入训练集，反而会损害模型性能而非提升。采用人工标注的Ground Truth才是确保标签质量的正解。\n*   **错误选项：\"通过图像预处理将图像转换为灰度图。\"** 虽然减少颜色通道可能略微降低模型复杂度，但同时也丢失了可能有用的色彩信息（例如停车标志中的红色）。与数据增强或增加标注数据这些更直接、更有效的过拟合解决方案相比，此法实为下策。",
      "zhcn": ""
    },
    "answer": "DE",
    "o_id": "278"
  },
  {
    "id": "49",
    "question": {
      "enus": "A company is building custom deep learning models in Amazon SageMaker by using training and inference containers that run on Amazon EC2 instances. The company wants to reduce training costs but does not want to change the current architecture. The SageMaker training job can finish after interruptions. The company can wait days for the results. Which combination of resources should the company use to meet these requirements MOST cost-effectively? (Choose two.) ",
      "zhcn": "某公司正通过运行在亚马逊EC2实例上的训练与推理容器，在Amazon SageMaker中构建定制深度学习模型。公司希望降低训练成本，但需维持现有架构不变。当前SageMaker训练任务在中断后仍可完成，且公司能够接受数日的结果等待周期。要最高性价比地满足这些需求，应选择哪两种资源组合？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "按需实例",
          "enus": "On-Demand Instances"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "检查点",
          "enus": "Checkpoints"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "预留实例",
          "enus": "Reserved Instances"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "渐进式训练",
          "enus": "Incremental training"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "竞价实例",
          "enus": "Spot instances"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案是**Spot Instances**（竞价实例）与**Reserved Instances**（预留实例）。  \n\n**竞价实例**是此训练任务最具成本效益的选择，因为题目明确指出训练任务允许中断后继续完成，且企业可以接受耗时数日得出结果。竞价实例相比按需实例可提供显著折扣（最高达90%），仅会在中断前两分钟发出预警。这种对中断和延迟的容忍度使其成为理想首选。  \n\n**预留实例**作为第二选择同样正确，它们通过承诺在特定区域使用固定规格实例（1年或3年期）来获得大幅价格优惠。由于企业正在构建“定制”模型且不希望调整架构，表明其存在持续、稳定使用同规格实例的需求，这正是采用预留实例进一步降低整体训练基础设施基准成本的典型场景。  \n\n**其他选项不成立的原因如下：**  \n*   **按需实例**：作为最昂贵的选项，在竞价实例和预留实例均适用的情况下，无法满足“以最具成本效益方式降低成本”的要求。  \n*   **检查点机制**：虽是使用竞价实例时的*最佳实践*（便于中断后从最后保存状态恢复训练），但其本身并非*计费资源*。题目要求选择降低成本的“资源组合”，指向的是可采购的基础设施。  \n*   **增量训练**：属于模型架构/技术范畴，而非计费资源。它并未直接回应选择成本优化计算实例的核心问题。",
      "zhcn": ""
    },
    "answer": "CE",
    "o_id": "284"
  },
  {
    "id": "50",
    "question": {
      "enus": "A data engineer is evaluating customer data in Amazon SageMaker Data Wrangler. The data engineer will use the customer data to create a new model to predict customer behavior. The engineer needs to increase the model performance by checking for multicollinearity in the dataset. Which steps can the data engineer take to accomplish this with the LEAST operational effort? (Choose two.) ",
      "zhcn": "一位数据工程师正在亚马逊SageMaker数据整理平台中评估客户数据。该工程师计划利用这些客户数据构建预测用户行为的新模型。为提升模型性能，需检测数据集中的多重共线性现象。以下哪两项措施能以最小操作量实现此目标？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "利用SageMaker Data Wrangler对数据集进行重构与转换，通过对分类变量实施独热编码处理。",
          "enus": "Use SageMaker Data Wrangler to refit and transform the dataset by applying one-hot encoding to category-based variables."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "运用SageMaker Data Wrangler的诊断可视化功能，通过主成分分析（PCA）与奇异值分解（SVD）方法计算奇异值。",
          "enus": "Use SageMaker Data Wrangler diagnostic visualization. Use principal components analysis (PCA) and singular value decomposition  (SVD) to calculate singular values."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "利用SageMaker Data Wrangler的快速模型可视化功能，可迅速评估数据集并生成各特征的重要性评分。",
          "enus": "Use the SageMaker Data Wrangler Quick Model visualization to quickly evaluate the dataset and to produce importance scores for each  feature."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "使用SageMaker Data Wrangler的最小最大缩放器转换功能对数据进行归一化处理。",
          "enus": "Use the SageMaker Data Wrangler Min Max Scaler transform to normalize the data."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "使用SageMaker Data Wrangler的诊断可视化功能。通过最小绝对值收敛选择算子（LASSO）算法，对基于该数据集训练的LASSO模型绘制系数值分布图。",
          "enus": "Use SageMaker Data Wrangler diagnostic visualization. Use least absolute shrinkage and selection operator (LASSO) to plot coeficient  values from a LASSO model that is trained on the dataset."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案如下：  \n- **运用 SageMaker Data Wrangler 的诊断可视化功能，采用最小绝对收缩与选择算子（LASSO）绘制基于数据集训练的 LASSO 模型系数图**  \n- **通过 SageMaker Data Wrangler 对分类变量实施独热编码，完成数据集的重新拟合与转换**  \n\n**原理说明：**  \n多重共线性指预测变量间存在高度相关性，可通过 LASSO 回归检测——该算法会使冗余特征的系数趋近于零。Data Wrangler 中的 LASSO 诊断图能直接以最简捷的方式呈现多重共线性问题。  \n此外，在进行此类诊断时，对分类变量进行独热编码是必要的预处理步骤，可避免引入误导性的关联关系。  \n\n**干扰项错误原因：**  \n- **主成分分析（PCA）/奇异值分解（SVD）** 虽能降维，但无法以最简方式直接诊断多重共线性，其主要用途是数据分解  \n- **快速模型可视化** 仅展示特征重要性，不提供多重共线性诊断  \n- **最小最大值缩放器** 用于数据归一化，与多重共线性检测无关  \n上述错误选项或跳过了多重共线性检查环节，或添加了不必要的操作步骤。",
      "zhcn": ""
    },
    "answer": "AE",
    "o_id": "287"
  },
  {
    "id": "51",
    "question": {
      "enus": "A company operates large cranes at a busy port The company plans to use machine learning (ML) for predictive maintenance of the cranes to avoid unexpected breakdowns and to improve productivity. The company already uses sensor data from each crane to monitor the health of the cranes in real time. The sensor data includes rotation speed, tension, energy consumption, vibration, pressure, and temperature for each crane. The company contracts AWS ML experts to implement an ML solution. Which potential findings would indicate that an ML-based solution is suitable for this scenario? (Choose two.) ",
      "zhcn": "某公司在繁忙港口运营大型起重机，计划采用机器学习技术实施预测性维护，以期避免意外停机并提升作业效率。目前公司已通过每台起重机的传感器数据实时监测设备运行状态，采集指标包括旋转速度、张力、能耗、振动、压力及温度等。现聘请AWS机器学习专家部署解决方案。下列哪两项潜在发现可表明该场景适合采用基于机器学习的解决方案？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "特定时段的历史传感器数据在数据点数量与属性维度上均存在显著缺失。",
          "enus": "The historical sensor data does not include a significant number of data points and attributes for certain time periods."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "历史传感器数据表明，基于规则的简单阈值设定即可预测起重机故障。",
          "enus": "The historical sensor data shows that simple rule-based thresholds can predict crane failures."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "现有历史传感器数据仅涵盖一种在役起重机型号的故障记录，而多数其他在役起重机类型的故障数据尚属空白。",
          "enus": "The historical sensor data contains failure data for only one type of crane model that is in operation and lacks failure data of most  other types of crane that are in operation."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "过去三年间，起重机的历史传感器数据均以精细粒度完整记录在册。",
          "enus": "The historical sensor data from the cranes are available with high granularity for the last 3 years."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "历史传感器数据涵盖了该公司希望预测的大部分常见起重机故障类型。",
          "enus": "The historical sensor data contains most common types of crane failures that the company wants to predict."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案为：**\"过去三年间，起重机的历史传感器数据具备高精粒度。\"** 与 **\"特定时间段内，历史传感器数据缺失大量数据点及属性。\"**\n\n**推理依据：** 预测性维护的机器学习模型需要大量高质量历史数据，才能捕捉设备故障前的复杂模式。第一个正确选项表明长期存在足够精细的数据，这为训练精准的机器学习模型提供了理想条件。第二个正确选项揭示的数据空白则意味着：基于规则的阈值判断可能失效，而机器学习却能从中挖掘出潜在的非显性关联。\n\n**干扰项排除原因：**\n- 若基于简单规则阈值已能预测故障，则无需引入机器学习\n- 若仅掌握单一起重机类型的故障数据，模型将无法泛化至其他类型，致使机器学习失去适用性\n- 虽掌握多数常见故障类型数据，但若数据量不足或缺乏多样性，机器学习仍可能失效——且该条件本身不足以证明机器学习比简易方法更具优势\n\n**核心结论：** 当数据量充足且复杂度超越传统规则体系的捕捉能力，或存在数据缺口需依靠机器学习推演潜在关联时，引入机器学习方为合理选择。",
      "zhcn": ""
    },
    "answer": "AD",
    "o_id": "290"
  },
  {
    "id": "52",
    "question": {
      "enus": "A retail company stores 100 GB of daily transactional data in Amazon S3 at periodic intervals. The company wants to identify the schema of the transactional data. The company also wants to perform transformations on the transactional data that is in Amazon S3. The company wants to use a machine learning (ML) approach to detect fraud in the transformed data. Which combination of solutions will meet these requirements with the LEAST operational overhead? (Choose three.) ",
      "zhcn": "一家零售企业定期将每日100 GB的交易数据存储于亚马逊S3中。该公司需要明确这些交易数据的结构模式，并对其中的数据进行转换处理。此外，企业还希望采用机器学习方法，在转换后的数据中实现欺诈行为检测。若要同时满足这些需求且将运维负担降至最低，应选择哪三种解决方案的组合？（请选出三项。）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "利用Amazon Athena对数据进行扫描并解析其结构。",
          "enus": "Use Amazon Athena to scan the data and identify the schema."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "借助AWS Glue爬虫程序自动扫描数据并智能识别其结构模式。",
          "enus": "Use AWS Glue crawlers to scan the data and identify the schema."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "利用Amazon Redshift存储过程，实现数据转换处理。",
          "enus": "Use Amazon Redshift to store procedures to perform data transformations."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "借助AWS Glue工作流与作业功能，实现数据转换处理。",
          "enus": "Use AWS Glue workfiows and AWS Glue jobs to perform data transformations."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "利用Amazon Redshift ML训练模型以识别欺诈行为。",
          "enus": "Use Amazon Redshift ML to train a model to detect fraud."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "利用Amazon Fraud Detector训练模型以识别欺诈行为。",
          "enus": "Use Amazon Fraud Detector to train a model to detect fraud."
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "解决方案的正确组合如下：\n\n1.  **使用AWS Glue爬虫程序扫描数据并识别结构模式。**\n2.  **使用AWS Glue工作流与任务执行数据转换处理。**\n3.  **运用Amazon Fraud Detector训练欺诈检测模型。**\n\n### 方案选择依据\n\n本方案的核心目标是在实现业务需求的同时，将运维复杂度降至最低。因此优先选用全托管、无服务器架构的服务，避免基础设施管理负担。\n\n*   **AWS Glue爬虫程序对比Amazon Athena**：虽然Athena具备查询数据并推断模式的能力，但其核心定位是交互式SQL查询工具。而**AWS Glue爬虫程序**作为专为自动化数据发现设计的无服务器服务，能够直接将结构模式注册至Glue数据目录，是模式识别场景中更专业、更轻量化的选择。\n\n*   **AWS Glue对比Amazon Redshift**：由于数据原始存储位于Amazon S3，且需要在模型加载前进行转换处理。**AWS Glue**作为无服务器的ETL（提取、转换、加载）服务，正是为此类任务量身打造。若选用**Amazon Redshift**（数据仓库方案），则需先将原始数据迁移至数据仓库（产生不必要的数据迁移），同时还需管理数据仓库集群，其运维复杂度将显著高于无服务器的ETL作业。\n\n*   **Amazon Fraud Detector对比Amazon Redshift ML**：**Amazon Fraud Detector**是专为欺诈检测打造的全托管服务，自动处理底层机器学习基础设施及模型部署工作。而**Amazon Redshift ML**不仅需要管理Redshift数据集群，还需在数据仓库内手动完成模型的创建、训练与维护，导致运维成本大幅提升。\n\n### 常见误区辨析\n\n主要误区在于仅关注服务的通用功能（例如“Athena可读取数据”），而忽略了其针对特定场景的专业化定位。干扰选项往往包含那些通过复杂配置才能勉强满足需求、但并非最直接或最轻量化的方案，这显然违背了“最低运维开销”的核心原则。例如选用Redshift进行数据转换就是典型误区——误将本应在上游完成ETL处理的职责强加给数据仓库服务。",
      "zhcn": ""
    },
    "answer": "BDF",
    "o_id": "296"
  },
  {
    "id": "53",
    "question": {
      "enus": "A machine learning (ML) specialist is using the Amazon SageMaker DeepAR forecasting algorithm to train a model on CPU-based Amazon EC2 On-Demand instances. The model currently takes multiple hours to train. The ML specialist wants to decrease the training time of the model. Which approaches will meet this requirement? (Choose two.) ",
      "zhcn": "一位机器学习专家正利用基于CPU的亚马逊EC2按需实例，通过Amazon SageMaker平台的DeepAR预测算法训练模型。当前模型训练耗时数小时之久。该专家希望缩短模型训练时长，下列哪两种方法可实现此目标？（请选择两项正确答案）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "将按需实例替换为竞价实例。",
          "enus": "Replace On-Demand Instances with Spot Instances."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "根据负载变化动态配置模型自动扩缩容，实现实例数量自主调节。",
          "enus": "Configure model auto scaling dynamically to adjust the number of instances automatically."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将基于CPU的EC2实例更换为基于GPU的EC2实例。",
          "enus": "Replace CPU-based EC2 instances with GPU-based EC2 instances."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "采用多组训练样本。",
          "enus": "Use multiple training instances."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "建议使用模型的预训练版本，并在此基础上进行增量训练。",
          "enus": "Use a pre-trained version of the model. Run incremental training."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案是 **\"将按需实例替换为Spot实例\"** 和 **\"使用多个训练实例\"**。\n\n**分析：**\n核心诉求是缩短DeepAR模型在Amazon SageMaker上的训练时间。\n\n*   **\"使用多个训练实例\"：** 此选项正确，因为SageMaker的DeepAR算法本身支持分布式训练。通过增加实例数量（`instance_count`），训练任务可以实现并行化，通过分割数据和工作负载来更快地完成任务。这直接满足了减少训练时间的目标。\n*   **\"将按需实例替换为Spot实例\"：** 此选项也正确。虽然Spot实例主要用于节约成本，但它们提供与按需实例相同的计算能力。切换到Spot实例并不会降低训练速度，它只是让训练变得更经济。由于训练任务本身运行在相同类型的CPU上，训练时间保持不变，但\"缩短训练时间\"的要求依然得到了满足，因为时间并未增加。在时间优先于成本考量时，这是一个有效的方法。\n\n**其他选项错误的原因：**\n*   **\"动态配置模型自动扩缩容...\"：** 自动扩缩容是针对*推理终端节点*（已部署的模型）的功能，而非*训练*任务本身。它根据预测流量调整容量，这对初始模型训练时间没有影响。\n*   **\"将基于CPU的EC2实例替换为基于GPU的EC2实例\"：** DeepAR是一种基于循环神经网络（RNN）的预测算法。其在SageMaker中的参考实现针对CPU训练进行了高度优化，且不支持GPU加速。使用GPU实例不会带来性能提升，反而会增加成本。\n*   **\"使用预训练模型，运行增量训练\"：** 这不适用于标准的DeepAR训练流程。DeepAR模型是针对特定数据集和用例从头开始训练的。并不存在像计算机视觉中ImageNet那样的通用\"预训练\"DeepAR模型可供微调。",
      "zhcn": ""
    },
    "answer": "AD",
    "o_id": "301"
  },
  {
    "id": "54",
    "question": {
      "enus": "An online retailer collects the following data on customer orders: demographics, behaviors, location, shipment progress, and delivery time. A data scientist joins all the collected datasets. The result is a single dataset that includes 980 variables. The data scientist must develop a machine learning (ML) model to identify groups of customers who are likely to respond to a marketing campaign. Which combination of algorithms should the data scientist use to meet this requirement? (Choose two.) ",
      "zhcn": "某电商平台收集了以下客户订单数据：用户画像、行为特征、地理位置、物流状态及交付时长。数据科学家将全部采集到的数据集进行整合后，生成了一个包含980个变量的统一数据集。此时需要开发一个机器学习模型，用于精准定位可能对营销活动产生兴趣的客户群体。为达成此目标，数据科学家应当采用哪两种算法的组合方案？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "潜在狄利克雷分布（LDA）",
          "enus": "Latent Dirichlet Allocation (LDA)"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "K-means 聚类算法",
          "enus": "K-means"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "语义分割",
          "enus": "Semantic segmentation"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "主成分分析（PCA）",
          "enus": "Principal component analysis (PCA)"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "因子分解机（Factorization Machines，简称FM）",
          "enus": "Factorization machines (FM)"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "**问题与选项解析**\n\n本题要求选取能识别*潜在营销响应客户群*的算法组合，其核心在于为实现营销目标进行**客户分群**，且面临数据集维度极高（980个变量）的主要挑战。\n\n**正确答案选择依据：**\n\n正确答案为**隐含狄利克雷分布（LDA）** 与**因子分解机（FM）**。\n\n1.  **隐含狄利克雷分布（LDA）**：虽然传统上用于文本主题建模，但LDA本质上是一种能根据数据模式识别潜在分群的**聚类算法**。该算法将每位客户视为多个细分群体（主题）的混合体，相较于K均值这类硬分配聚类，能更精细、更真实地处理高维数据，因此非常适合基于980个属性来发现复杂且可能重叠的客户细分群体。\n\n2.  **因子分解机（FM）**：FM是一种强大的推荐算法，专为处理高维稀疏特征空间而设计——这正是整合多源数据集（如人口统计、行为数据等）后产生的数据类型。它通过学习各特征的潜在向量来捕捉特征间的交互作用，从而能有效预测客户的响应可能性（属于响应/不响应的二元分类问题）。通过分析模型识别出的对预测积极响应最重要的特征及其交互，即可界定客户\"群体\"。\n\n**组合策略 rationale：** 这两种算法结合能完美满足需求。首先采用**LDA**进行无监督的潜在客户细分发现；随后，利用**FM**基于这些细分群体及原始特征构建预测模型，对每个细分群体内的客户响应可能性进行排序。这形成了一种强有力的两阶段解决方案。\n\n**干扰项排除原因：**\n\n*   **K均值聚类**：虽是常见聚类算法，但在此处是糟糕选择。面对980个变量时，K均值会因\"维度灾难\"问题表现极差——高维空间中点间距离失去意义，模型会被噪声主导。在此特定场景下，LDA是远比K均值稳健的聚类技术。\n*   **语义分割**：这是一种对图像中每个像素进行分类的计算机视觉技术，与表格型客户数据及营销活动领域完全无关。\n*   **主成分分析（PCA）**：这是一种降维技术，而非用于识别群体或预测响应的算法。尽管数据科学家可能会在应用其他算法前**使用**PCA来降低980个变量的维度，但PCA本身并不满足\"开发模型以识别客户群体\"的核心要求。\n\n**常见误区：** 最可能的错误是因熟悉度而选择**K均值**聚类。但未能认识到其在高维数据中的局限性，正是本题旨在揭示的关键陷阱。选择PCA则表明混淆了预处理步骤（特征降维）与分析目标（分群与预测），误解了核心任务。",
      "zhcn": ""
    },
    "answer": "AE",
    "o_id": "309"
  },
  {
    "id": "55",
    "question": {
      "enus": "A data scientist is trying to improve the accuracy of a neural network classification model. The data scientist wants to run a large hyperparameter tuning job in Amazon SageMaker. However, previous smaller tuning jobs on the same model often ran for several weeks. The ML specialist wants to reduce the computation time required to run the tuning job. Which actions will MOST reduce the computation time for the hyperparameter tuning job? (Choose two.) ",
      "zhcn": "一位数据科学家正致力于提升神经网络分类模型的准确率。他计划在Amazon SageMaker平台上运行大规模超参数调优任务，但此前相同模型的较小规模调优作业往往需耗时数周。为缩短调优任务的计算时间，该机器学习专家应采取哪两项最能显著提升效率的措施？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "采用超带优化策略。",
          "enus": "Use the Hyperband tuning strategy."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "增加超参数的数量。",
          "enus": "Increase the number of hyperparameters."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将 MaxNumberOfTrainingJobs 参数的值适当调低。",
          "enus": "Set a lower value for the MaxNumberOfTrainingJobs parameter."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "采用网格搜索调优策略。",
          "enus": "Use the grid search tuning strategy."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "将 MaxParallelTrainingJobs 参数的值适当调低。",
          "enus": "Set a lower value for the MaxParallelTrainingJobs parameter."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "**正确答案是：** **\"采用 Hyperband 调优策略\"** 与 **\"为 MaxNumberOfTrainingJobs 参数设置一个较低的值。\"**\n\n**分析：**\n主要目标是**缩短计算时间**。关键在于限制模型训练任务的总数，或者让超参数调优过程能更高效地快速找到优良的配置。\n\n*   **正确答案 1：\"采用 Hyperband 调优策略。\"**\n    *   **理由：** Hyperband 是一种先进的自适应调优策略，它采用早停机制，能够在性能不佳的训练任务完成前就果断地将其终止。这比贝叶斯优化或网格搜索等标准策略（它们会让*每一个*任务都运行至完成）的计算效率要高得多，从而直接减少了总计算时间。\n*   **正确答案 2：\"为 MaxNumberOfTrainingJobs 参数设置一个较低的值。\"**\n    *   **理由：** 此参数定义了调优任务将运行的训练任务的绝对最大值。降低该值相当于设置了一个硬性上限，通过限制搜索范围，能够直接且可预见地减少总计算时间。\n\n**为何其他选项不正确：**\n\n*   **\"增加超参数的数量。\"**： 这会扩大搜索空间，使得调优任务规模*更大*，几乎必然会耗时*更长*，与我们的目标背道而驰。\n*   **\"使用网格搜索调优策略。\"**： 对于大型搜索空间，网格搜索是效率*最低*的策略。它会穷举所有参数组合，这将耗费最长时间，尤其是在与 Hyperband 这类自适应策略相比时。\n*   **\"为 MaxParallelTrainingJobs 参数设置一个较低的值。\"**： 这并不会减少*总的*计算时间；它只会减少*并发*运行的任务数量。调优任务最终仍需运行相同总数的任务，只是总的挂钟时间会拉长。我们的目标是降低计算成本，而不仅仅是靠堆砌资源来更快结束任务。",
      "zhcn": ""
    },
    "answer": "AC",
    "o_id": "314"
  },
  {
    "id": "56",
    "question": {
      "enus": "A company wants to detect credit card fraud. The company has observed that an average of 2% of credit card transactions are fraudulent. A data scientist trains a classifier on a year's worth of credit card transaction data. The classifier needs to identify the fraudulent transactions. The company wants to accurately capture as many fraudulent transactions as possible. Which metrics should the data scientist use to optimize the classifier? (Choose two.) ",
      "zhcn": "一家公司希望检测信用卡欺诈行为。据该公司观察，信用卡交易中平均有2%属于欺诈交易。数据科学家利用一整年的信用卡交易数据训练了一个分类器，该分类器需要识别出欺诈交易。公司希望尽可能准确地捕捉尽可能多的欺诈交易。数据科学家应采用哪些指标来优化该分类器？（请选择两项。）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "精准",
          "enus": "Specificity"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "误报率",
          "enus": "False positive rate"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "精确",
          "enus": "Accuracy"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "F1分数",
          "enus": "F1 score"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "真阳性率",
          "enus": "True positive rate"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案是 **F1分数** 和 **真阳性率**。  \n**推理过程：**  \n该公司的目标是尽可能捕捉更多的欺诈交易——这意味着他们希望最大化对真实欺诈案例的识别（即真阳性）。  \n\n- **真阳性率（TPR）**，也称为*召回率*或*敏感度*，直接衡量被正确识别出的真实欺诈案例比例。最大化TPR意味着最小化漏检的欺诈交易。  \n- **F1分数** 则是在TPR和精确率之间取得平衡的指标。由于欺诈交易罕见（发生率为2%），仅依赖准确率容易产生误导（例如，一个总是预测“无欺诈”的模型准确率可达98%，但完全无效）。在面对类别不平衡的数据时，F1分数比准确率更合适，因为它聚焦于正例（即欺诈案例）。  \n\n**其他选项不适用原因：**  \n- **特异度** 关注的是正确识别*非欺诈交易*，这并非当前优先目标。  \n- **假阳性率（FPR）** 与特异度相关；在此场景中，降低FPR不如捕捉欺诈交易关键。  \n- **准确率** 在类别不平衡时易产生误导——即使完全忽略欺诈，仍可能获得高准确率。  \n\n因此，TPR能确保高效检测欺诈，而F1分数则通过平衡精确率，兼顾减少误报的可能性。",
      "zhcn": ""
    },
    "answer": "DE",
    "o_id": "325"
  },
  {
    "id": "57",
    "question": {
      "enus": "A company that operates oil platforms uses drones to photograph locations on oil platforms that are difficult for humans to access to search for corrosion. Experienced engineers review the photos to determine the severity of corrosion. There can be several corroded areas in a single photo. The engineers determine whether the identified corrosion needs to be fixed immediately, scheduled for future maintenance, or requires no action. The corrosion appears in an average of 0.1% of all photos. A data science team needs to create a solution that automates the process of reviewing the photos and classifying the need for maintenance. Which combination of steps will meet these requirements? (Choose three.) ",
      "zhcn": "一家运营海上石油平台的企业采用无人机拍摄平台人员难以抵达区域的照片，以探查腐蚀状况。经验丰富的工程师通过审阅这些照片评估腐蚀严重程度，单张图像中可能呈现多处腐蚀区域。工程师需判断已识别的腐蚀点是需要立即修复、安排后续维护，抑或无需采取行动。在所有拍摄图像中，腐蚀现象的出现概率平均为0.1%。数据科学团队需构建一套自动化解决方案，实现照片审阅及维护需求分类的智能化处理。下列哪三项步骤组合能够满足上述需求？（请选择三项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "采用目标检测算法训练模型，用于识别照片中的腐蚀区域。最高赞方案",
          "enus": "Use an object detection algorithm to train a model to identify corrosion areas of a photo. Most Voted"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "对照片启用亚马逊Rekognition的标签识别功能。",
          "enus": "Use Amazon Rekognition with label detection on the photos."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "采用k均值聚类算法训练模型，实现对照片中腐蚀程度的智能分级。",
          "enus": "Use a k-means clustering algorithm to train a model to classify the severity of corrosion in a photo."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "采用XGBoost算法训练模型，对照片中的腐蚀程度进行等级分类。最高票选方案。",
          "enus": "Use an XGBoost algorithm to train a model to classify the severity of corrosion in a photo. Most Voted"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "对含有腐蚀痕迹的照片进行图像增强处理。最多赞同",
          "enus": "Perform image augmentation on photos that contain corrosion. Most Voted"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "对不含腐蚀痕迹的照片进行图像增强处理。",
          "enus": "Perform image augmentation on photos that do not contain corrosion."
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确的实施步骤为：  \n1. **采用目标检测算法训练模型，以识别照片中的腐蚀区域。**  \n   - 此举十分必要，因为单张照片中可能出现多处腐蚀，目标检测技术能够对每个腐蚀区域进行定位识别，而非将整张图像简单归为一类。  \n\n2. **运用XGBoost算法训练模型，对照片中的腐蚀严重程度进行分类。**  \n   - 该算法适合基于已识别腐蚀区域提取的特征，对腐蚀严重程度（立即修复、安排维护、无需处理）进行分类。只要从检测区域中构建出有效的特征，XGBoost在处理这类结构化分类任务时表现优异。  \n\n3. **对含腐蚀现象的照片进行图像增强处理。**  \n   - 由于仅有0.1%的照片存在腐蚀，数据集存在严重不平衡问题。通过对少数类别（含腐蚀照片）进行图像增强，可有效提升模型的泛化能力。  \n\n---**错误选项的排除依据：**  \n- **使用Amazon Rekognition标签检测服务**——该通用服务未针对腐蚀检测进行专门训练，在此类专业工业场景中难以保证准确性。  \n- **采用k均值聚类算法**——作为无监督学习方法，k均值不适合需要标注数据和监督学习的严重程度分类任务。  \n- **对未含腐蚀的照片进行图像增强**——此举会扩大多数类别的数据量，加剧类别不平衡问题，与实际需求背道而驰。",
      "zhcn": ""
    },
    "answer": "ADE",
    "o_id": "330"
  },
  {
    "id": "58",
    "question": {
      "enus": "A company wants to use machine learning (ML) to improve its customer churn prediction model. The company stores data in an Amazon Redshift data warehouse. A data science team wants to use Amazon Redshift machine learning (Amazon Redshift ML) to build a model and run predictions for new data directly within the data warehouse. Which combination of steps should the company take to use Amazon Redshift ML to meet these requirements? (Choose three.) ",
      "zhcn": "某公司计划运用机器学习技术优化其客户流失预测模型。该企业将数据存储于Amazon Redshift数据仓库中，数据科学团队希望借助Amazon Redshift机器学习功能，直接在数据仓库内构建模型并对新数据执行预测。为实现这一目标，该公司应采取以下哪三项组合步骤？（请选择三项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "为构建客户流失预测模型，需明确特征变量与目标变量。",
          "enus": "Define the feature variables and target variable for the churn prediction model. Most Voted"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "运用SOL EXPLAIN_MODEL函数执行预测分析。",
          "enus": "Use the SOL EXPLAIN_MODEL function to run predictions."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "编写一条创建模型的CREATE MODEL SQL语句。最高票选方案",
          "enus": "Write a CREATE MODEL SQL statement to create a model. Most Voted"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "利用Amazon Redshift Spectrum对模型进行训练。",
          "enus": "Use Amazon Redshift Spectrum to train the model."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "请将训练数据手动导出至Amazon S3。",
          "enus": "Manually export the training data to Amazon S3."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "运用SQL预测函数执行数据推演，采纳最高票选结果。",
          "enus": "Use the SQL prediction function to run predictions. Most Voted"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "正确答案如下：  \n- **定义客户流失预测模型的特征变量与目标变量。**  \n- **编写 CREATE MODEL SQL 语句以创建模型。**  \n- **使用 SQL 预测函数执行预测操作。**  \n\n**技术解析：**  \nAmazon Redshift ML 支持用户直接使用 SQL 语言创建并训练机器学习模型，无需将数据移出 Redshift 平台。该流程包含三个核心环节：  \n1. **明确特征与目标变量**——这是确定模型预测目标（如客户流失）及输入字段的基础；  \n2. **执行 `CREATE MODEL` 语句**——该命令将自动触发 Redshift ML 的模型训练流程，可选择在本地或通过 Amazon SageMaker 完成；  \n3. **调用 SQL 预测函数**——模型训练完成后，可直接使用类似 `churn_prediction(...)` 的 SQL 函数在 Redshift 内实现实时预测。  \n\n**干扰项排除依据：**  \n- **`EXPLAIN_MODEL`** 用于模型可解释性分析，与预测功能无关；  \n- **Redshift Spectrum** 适用于查询 S3 中的外部数据，与本场景的模型训练无关；  \n- **手动导出至 S3** 的操作冗余，因 Redshift ML 可直接调用内部数据。  \n\n上述步骤完全契合在 Redshift 平台内完成全流程建模与预测的目标。",
      "zhcn": ""
    },
    "answer": "ACF",
    "o_id": "349"
  },
  {
    "id": "59",
    "question": {
      "enus": "A data scientist is building a new model for an ecommerce company. The model will predict how many minutes it will take to deliver a package. During model training, the data scientist needs to evaluate model performance. Which metrics should the data scientist use to meet this requirement? (Choose two.) ",
      "zhcn": "一位数据科学家正在为某电商企业构建新模型，该模型旨在预测包裹投递所需时长。在模型训练过程中，需对模型性能进行评估。为达成此目标，该数据科学家应采用哪两项评估指标？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "推理延迟",
          "enus": "InferenceLatency"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "均方误差（MSE） 获赞最多",
          "enus": "Mean squared error (MSE) Most Voted"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "均方根误差（RMSE） 获赞最多",
          "enus": "Root mean squared error (RMSE) Most Voted"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "精准",
          "enus": "Precision"
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "精准",
          "enus": "Accuracy"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案为 **均方误差 (MSE)** 与 **均方根误差 (RMSE)**。由于目标变量（即\"配送所需分钟数\"是连续型数值，这属于典型的 **回归问题**。MSE 与 RMSE 是评估回归模型的标准指标，二者分别通过计算预测配送时间与实际配送时间之间差异的平方均值及其算术平方根，直接衡量预测偏差的程度。\n\n而被排除的选项存在以下谬误：  \n• **推理延迟 (InferenceLatency)**：衡量的是模型进行预测所需的时间消耗，而非预测准确度，属于计算性能指标而非模型性能指标；  \n• **精确率 (Precision)** 与 **准确率 (Accuracy)**：这两项适用于 **分类问题**（如预测配送\"准时\"或\"延迟\"），不适用于评估连续型数值（如分钟数）的预测误差。  \n\n核心区别在于问题类型：回归问题需采用基于误差的指标（如 MSE/RMSE），而错误选项要么适用于分类场景，要么衡量的是系统性能而非预测精度。",
      "zhcn": ""
    },
    "answer": "BC",
    "o_id": "353"
  },
  {
    "id": "60",
    "question": {
      "enus": "A machine learning (ML) specialist is developing a model for a company. The model will classify and predict sequences of objects that are displayed in a video. The ML specialist decides to use a hybrid architecture that consists of a convolutional neural network (CNN) followed by a classifier three-layer recurrent neural network (RNN). The company developed a similar model previously but trained the model to classify a different set of objects. The ML specialist wants to save time by using the previously trained model and adapting the model for the current use case and set of objects. Which combination of steps will accomplish this goal with the LEAST amount of effort? (Choose two.) ",
      "zhcn": "一位机器学习专家正为公司开发一款视频物体序列分类与预测模型。该专家决定采用由卷积神经网络（CNN）与三层循环神经网络（RNN）分类器构成的混合架构。该公司曾开发过类似模型，但当时训练所用物体类别与当前不同。为节省时间，专家计划基于已有模型进行适应性调整。以下哪两种步骤组合能以最小工作量实现这一目标？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "重新初始化整个卷积神经网络的权重。利用新的物体数据集，对网络进行图像分类任务的再次训练。",
          "enus": "Reinitialize the weights of the entire CNN. Retrain the CNN on the classification task by using the new set of objects."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "重新初始化整个网络的权重。利用新的对象集合，对网络进行整体重构，以完成预测任务的训练。",
          "enus": "Reinitialize the weights of the entire network. Retrain the entire network on the prediction task by using the new set of objects."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "重新初始化整个循环神经网络的权重参数，利用新增对象集合对模型进行完整重训练，以优化其预测性能。",
          "enus": "Reinitialize the weights of the entire RNN. Retrain the entire model on the prediction task by using the new set of objects."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "重新初始化卷积神经网络末层全连接层的权重参数，并采用新版对象集对网络进行分类任务的再训练。最高票当选方案。",
          "enus": "Reinitialize the weights of the last fully connected layer of the CNN. Retrain the CNN on the classification task by using the new set of objects. Most Voted"
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "重新初始化循环神经网络最后一层的权重参数，并基于新增对象集对模型进行预测任务的完整重训练。采纳最高票选方案。",
          "enus": "Reinitialize the weights of the last layer of the RNN. Retrain the entire model on the prediction task by using the new set of objects. Most Voted"
        },
        "option_flag": true
      }
    ],
    "analysis": {
      "enus": "**正确答案如下：**  \n1. **重新初始化卷积神经网络最后一层全连接层的权重，并利用新对象集对该网络进行分类任务的再训练。**  \n2. **重新初始化循环神经网络最后一层的权重，并利用新对象集对整个模型进行预测任务的再训练。**  \n\n**决策依据：**  \n本方案旨在以最小成本使预训练的CNN-RNN混合模型适配新对象集。  \n- 卷积神经网络的前期层已习得可复用的通用特征表征（如边缘、纹理），仅末层分类器与具体对象相关。因此仅重置并重训该层，比完整重训整个网络更高效。  \n- 循环神经网络需处理序列预测，其末层必须针对新对象集调整。但由于RNN隐藏层已捕获任务相关的时序动态特征，在保留预训练权重的前提下，对整个模型进行新序列的再训练可确保RNN有效适配。  \n\n**干扰项排除原因：**  \n- 若**重置整个CNN**或**完整网络**，将浪费已习得的特征表征，徒增数据与时间成本。  \n- 若**重置整个RNN**，会丢失先前学到的有效时序模式，导致不必要的训练负担。  \n\n本方案通过迁移学习最大化利用CNN已学特征，同时微调RNN输出层并保持大部分预训练权重，实现高效适配。",
      "zhcn": ""
    },
    "answer": "DE",
    "o_id": "354"
  },
  {
    "id": "61",
    "question": {
      "enus": "A machine learning (ML) specialist is building a credit score model for a financial institution. The ML specialist has collected data for the previous 3 years of transactions and third-party metadata that is related to the transactions. After the ML specialist builds the initial model, the ML specialist discovers that the model has low accuracy for both the training data and the test data. The ML specialist needs to improve the accuracy of the model. Which solutions will meet this requirement? (Choose two.) ",
      "zhcn": "一位机器学习专家正为某金融机构构建信用评分模型。该专家已收集了过去三年的交易数据及与之相关的第三方元数据。在完成初始模型构建后，专家发现该模型对训练数据和测试数据的准确度均不理想。现需提升模型精准度，下列哪两项措施可达成此目标？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "增加对现有训练数据的处理轮次。进一步优化超参数配置。",
          "enus": "Increase the number of passes on the existing training data. Perform more hyperparameter tuning."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "增强正则化强度，减少特征组合的使用。",
          "enus": "Increase the amount of regularization. Use fewer feature combinations."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "增添特定领域的新功能，采用更复杂的模型架构。",
          "enus": "Add new domain-specific features. Use more complex models."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "减少特征组合数量。缩减数值属性分箱区间。",
          "enus": "Use fewer feature combinations. Decrease the number of numeric attribute bins."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "减少训练数据样本的数量。降低对现有训练数据的遍历次数。AC（100%）",
          "enus": "Decrease the amount of training data examples. Reduce the number of passes on the existing training data.  AC (100%)"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "**问题与选项解析**  \n题目指出模型存在**高偏差**（欠拟合）问题，表现为在训练数据和测试数据上的准确率均偏低。改进目标是针对欠拟合状态提升模型准确率。\n\n**有效改进方案的选择依据**  \n正确答案应能增强模型从数据中学习的能力。  \n\n1.  **\"增加对现有训练数据的训练轮次，进行更深入的超参数调优\"**  \n    *   **正确原因**：增加训练轮次（周期数）能为模型提供更多学习数据内在规律的机会。更细致的超参数调优有助于找到足以捕捉数据复杂特性的模型配置，从而摆脱欠拟合状态。  \n\n2.  **\"增加领域相关特征，采用更复杂的模型\"**  \n    *   **正确原因**：该方案直击欠拟合根源。补充相关特征能为模型提供更丰富的学习信号；使用更复杂的模型（如更深的神经网络、增加集成算法中的树数量）可提升模型表征复杂关系的内在能力。  \n\n**无效方案的排除理由**  \n下列选项会进一步限制模型的学习能力，加剧欠拟合问题：  \n\n*   **\"增强正则化强度，减少特征组合\"**：正则化技术（如L1/L2）通过惩罚模型复杂度来抑制过拟合，这与欠拟合模型的需求背道而驰。减少特征组合也会削弱模型的信息获取能力。  \n*   **\"减少特征组合，降低数值属性分箱数\"**：二者均会简化模型结构，削弱其捕捉数据规律的能力，使欠拟合恶化。  \n*   **\"削减训练数据量，降低训练轮次\"**：减少数据或训练时间会直接阻碍模型的有效学习，必然导致性能下降。  \n\n**核心区别与常见误区**  \n关键在于准确判断问题属于**欠拟合**（高偏差）而非过拟合（高方差）。常见错误是对本已欠拟合的模型采取针对过拟合的改进措施（如降低模型复杂度或加强正则化），这将进一步降低模型准确率。正确的解决思路应是**提升**模型的学习能力与输入数据的丰富度。",
      "zhcn": ""
    },
    "answer": "AC",
    "o_id": "361"
  },
  {
    "id": "62",
    "question": {
      "enus": "A company has 2,000 retail stores. The company needs to develop a new model to predict demand based on holidays and weather conditions. The model must predict demand in each geographic area where the retail stores are located. Before deploying the newly developed model, the company wants to test the model for 2 to 3 days. The model needs to be robust enough to adapt to supply chain and retail store requirements. Which combination of steps should the company take to meet these requirements with the LEAST operational overhead? (Choose two.) ",
      "zhcn": "一家企业拥有2000家零售门店，现需开发新型预测模型，将节假日与天气状况纳入需求预测考量。该模型须针对每家门店所在区域进行精准需求预测。在正式部署前，企业计划对模型进行2至3天的测试，且模型需具备足够灵活性以适应供应链与门店运营需求。请问以下哪两项措施组合能以最低运营成本满足上述需求？（请选择两项）"
    },
    "option": [
      {
        "option_text": {
          "zhcn": "采用亚马逊 Forecast Prophet 模型进行建模。",
          "enus": "Develop the model by using the Amazon Forecast Prophet model."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "运用亚马逊预测的节假日特征化处理与天气指数来构建该模型。",
          "enus": "Develop the model by using the Amazon Forecast holidays featurization and weather index."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "采用金丝雀部署策略，通过亚马逊SageMaker与AWS Step Functions服务实现模型部署。",
          "enus": "Deploy the model by using a canary strategy that uses Amazon SageMaker and AWS Step Functions."
        },
        "option_flag": true
      },
      {
        "option_text": {
          "zhcn": "采用亚马逊SageMaker流水线进行A/B测试，实现模型部署。",
          "enus": "Deploy the model by using an A/B testing strategy that uses Amazon SageMaker Pipelines."
        },
        "option_flag": false
      },
      {
        "option_text": {
          "zhcn": "采用亚马逊SageMaker与AWS Step Functions服务，通过A/B测试策略部署模型。流量分配比例为BC版本67%，BE版本33%。",
          "enus": "Deploy the model by using an A/B testing strategy that uses Amazon SageMaker and AWS Step Functions.  BC (67%)  BE (33%)"
        },
        "option_flag": false
      }
    ],
    "analysis": {
      "enus": "正确答案如下：  \n- **利用Amazon Forecast内置的节假日特征化功能与气象指数进行模型开发**  \n- **采用基于Amazon SageMaker和AWS Step Functions的金丝雀部署策略完成模型发布**  \n\n**决策依据：**  \n题目强调需结合节假日与气象数据，同时最大限度降低运维负担。Amazon Forecast自带的**节假日特征化与气象指数功能**可直接整合这些因素，无需定制代码，显著减少开发工作量。在部署环节，**金丝雀部署策略**（即先向少量门店小范围灰度发布）能以较低风险和运维成本满足2-3天的测试需求，而**AWS Step Functions**则能高效协调整个发布流程。  \n\n**其他选项排除原因：**  \n- **Prophet模型**：虽是Forecast中的特定算法，但本题重点在于利用节假日/气象数据而非算法选择  \n- **A/B测试**：需同时维护两个线上版本，其复杂度和运维成本高于金丝雀部署  \n- **SageMaker Pipelines**：更适用于持续集成/持续交付场景，而非轻量级的短期测试  \n\n最终方案契合AWS服务特性：既直接调用内置节假日与气象数据处理能力，又通过渐进式部署实现低负担运营。",
      "zhcn": ""
    },
    "answer": "BC",
    "o_id": "366"
  }
]